Using TensorFlow backend.
2018-07-09 11:19:08.323048: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-07-09 11:19:08.866173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-07-09 11:19:09.114655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:0b:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-07-09 11:19:09.390417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:0e:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-07-09 11:19:09.667166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:11:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-07-09 11:19:09.680469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3
2018-07-09 11:19:14.872645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-09 11:19:14.873002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3 
2018-07-09 11:19:14.873015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y Y Y 
2018-07-09 11:19:14.873020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N Y Y 
2018-07-09 11:19:14.873025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   Y Y N Y 
2018-07-09 11:19:14.873039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   Y Y Y N 
2018-07-09 11:19:14.874584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
2018-07-09 11:19:15.051211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0b:00.0, compute capability: 6.0)
2018-07-09 11:19:15.232518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 15135 MB memory) -> physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0e:00.0, compute capability: 6.0)
2018-07-09 11:19:15.414893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 15135 MB memory) -> physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:11:00.0, compute capability: 6.0)
>>> Imports:
#coding=utf-8

from __future__ import print_function

try:
    import numpy as np
except:
    pass

try:
    import h5py
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation
except:
    pass

try:
    from keras.models import Sequential
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from keras.utils import to_categorical
except:
    pass

try:
    from keras.layers import LeakyReLU, ELU
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

try:
    from workingwithpython import *
except:
    pass

try:
    from sklearn.model_selection import train_test_split
except:
    pass

try:
    from sklearn import preprocessing
except:
    pass

try:
    from macros_AWS import scale_x
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'add': hp.choice('add', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'add_1': hp.choice('add_1', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'add_2': hp.choice('add_2', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'optimizer': hp.choice('optimizer', ['adam','nadam','adamax']),
    }

>>> Data
   1: 
   2: """
   3: Data providing function:
   4: 
   5: This function is separated from create_model() so that hyperopt
   6: won't reload data for each evaluation run.
   7: """
   8: #(x_train, y_train), (x_test, y_test) = mnist.load_data()
   9: #x_train = x_train.reshape(60000, 784)
  10: #x_test = x_test.reshape(10000, 784)
  11: #x_train = x_train.astype('float32')
  12: #x_test = x_test.astype('float32')
  13: #x_train /= 255
  14: #x_test /= 255
  15: #nb_classes = 10
  16: #y_train = np_utils.to_categorical(y_train, nb_classes)
  17: #y_test = np_utils.to_categorical(y_test, nb_classes)
  18: from sklearn.model_selection import train_test_split
  19: from sklearn import preprocessing
  20: from macros_AWS import scale_x
  21: data_directory = '/home/rice/jmc32/Gridsearch_Data/'
  22: data_sample = 'PtRegression_for_DNN_Vars_MODE_15_noBitCompr_RPC_1m_redo.npy'
  23: scaler = 'robust'
  24: totalset = np.load(data_directory + data_sample)
  25: dataset, testset = train_test_split(totalset, test_size = 0.1)
  26: # Split into input (X) and output (Y) variables
  27: x_train_prescale = dataset[:,1:]
  28: y_train = dataset[:,0]
  29: x_test_prescale = testset[:,1:]
  30: y_test = testset[:,0]
  31: # Scale
  32: print(y_train.shape)
  33: print(y_test.shape)
  34: #print(numpy.matrix(y_train))
  35: x_train, x_test = scale_x(x_train_prescale, x_test_prescale, scaler)
  36: #min_max_scaler = preprocessing.MinMaxScaler()
  37: #x_test = min_max_scaler.fit_transform(x_train)
  38: #y_test = min_max_scaler.fit_transform(y_train)
  39: #x_train = min_max_scaler.fit_transform(x_train)
  40: #y_train = min_max_scaler.fit_transform(y_train)
  41: #x_test=x_test.reshape((900000, 7))
  42: #y_test=y_test.reshape((y_test.shape[0], 7))
  43: #x_train=x_train.reshape((x_train.shape[0], 7))
  44: #y_train=y_train.reshape((y_train.shape[0],  7))
  45: 
  46: print(x_train.shape)
  47: print(x_test.shape)
  48: #y_train= to_categorical(y_train)
  49: #y_test= to_categorical(y_test)
  50: #x_train= to_categorical(x_train)
  51: #x_test= to_categorical(x_test)
  52: 
  53: 
  54: 
  55: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     """
   4:     Model providing function:
   5: 
   6:     Create Keras model with double curly brackets dropped-in as needed.
   7:     Return value has to be a valid python dictionary with two customary keys:
   8:         - loss: Specify a numeric evaluation metric to be minimized
   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible
  10:     The last one is optional, though recommended, namely:
  11:         - model: specify the model just created so that we can later use it again.
  12:     """
  13:     model = Sequential()
  14:     model.add(Dense(100, input_dim=7))
  15:     model.add(space['add'])
  16:     model.add(Dense(100))
  17:     model.add(space['add_1'])
  18:     model.add(Dense(100))
  19:     model.add(space['add_2'])
  20: 
  21:     model.add(Dense(1))  
  22:     model.add(Activation('sigmoid'))
  23:   
  24:   
  25:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],
  26:                      optimizer=space['optimizer'])
  27: 
  28:     
  29:     model.fit(x_train, y_train,
  30:               batch_size=100,
  31:               epochs=2,
  32:               verbose=2,
  33:               validation_data=(x_test, y_test))
  34:     score, acc = model.evaluate(x_test, y_test, verbose=0)
  35:     print('Test accuracy:', acc)
  36:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}
  37: 
(900000,)
(100000,)
(900000, 7)
(100000, 7)
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 42s - loss: 0.1812 - acc: 0.9274 - val_loss: 0.1717 - val_acc: 0.9308
Epoch 2/2
 - 34s - loss: 0.1629 - acc: 0.9343 - val_loss: 0.1643 - val_acc: 0.9333
Test accuracy: 0.93332
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 36s - loss: 0.1774 - acc: 0.9286 - val_loss: 0.1659 - val_acc: 0.9325
Epoch 2/2
 - 35s - loss: 0.1609 - acc: 0.9345 - val_loss: 0.1581 - val_acc: 0.9356
Test accuracy: 0.93559
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 40s - loss: 0.1781 - acc: 0.9282 - val_loss: 0.1637 - val_acc: 0.9332
Epoch 2/2
 - 39s - loss: 0.1626 - acc: 0.9341 - val_loss: 0.1611 - val_acc: 0.9340
Test accuracy: 0.93396
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 39s - loss: 0.1745 - acc: 0.9305 - val_loss: 0.1643 - val_acc: 0.9341
Epoch 2/2
 - 38s - loss: 0.1604 - acc: 0.9349 - val_loss: 0.1604 - val_acc: 0.9345
Test accuracy: 0.93451
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 36s - loss: 0.1829 - acc: 0.9259 - val_loss: 0.1699 - val_acc: 0.9312
Epoch 2/2
 - 35s - loss: 0.1621 - acc: 0.9343 - val_loss: 0.1599 - val_acc: 0.9355
Test accuracy: 0.93547
(900000,)
(100000,)
(900000, 7)
(100000, 7)
Traceback (most recent call last):
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/DUMMYHyperasexamplerun.py", line 129, in <module>
    numpy.savetxt(outfile_predict, model_predictions)
NameError: name 'numpy' is not defined
/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/compare_truth.py:3: UserWarning: loadtxt: Empty input file: "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/predictions/model_class_predictions_1m_kclassify.txt"
  predicts = np.loadtxt('/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/predictions/model_class_predictions_1m_kclassify.txt')
/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/compare_truth.py:6: UserWarning: loadtxt: Empty input file: "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/predictions/model_class_true_1m_kclassify.txt"
  truth = np.loadtxt('/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/predictions/model_class_true_1m_kclassify.txt')
('True negative total is ', 0, 'out of', 0)
('True positive total is ', 0)
('False negative total is ', 0)
('False positive total is ', 0)
('Any missed ones? ', 0)
Traceback (most recent call last):
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/compare_truth.py", line 41, in <module>
    file.write('Efficiency = %f \n' %(float(true_pos)/float(true_pos+false_neg)))
ZeroDivisionError: float division by zero
