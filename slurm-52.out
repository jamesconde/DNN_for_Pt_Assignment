Using TensorFlow backend.
2018-06-28 01:50:04.145214: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-06-28 01:50:05.196867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:05:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 01:50:05.876356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:08:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 01:50:06.562388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:0d:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 01:50:07.250941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:13:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 01:50:07.969763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 4 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:83:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 01:50:08.706200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 5 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:89:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 01:50:09.460394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 6 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8e:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 01:50:10.215708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 7 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:91:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 01:50:10.239240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2018-06-28 01:50:13.590461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-28 01:50:13.590519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3 4 5 6 7 
2018-06-28 01:50:13.590530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y Y Y N N N N 
2018-06-28 01:50:13.590537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N Y Y N N N N 
2018-06-28 01:50:13.590544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   Y Y N Y N N N N 
2018-06-28 01:50:13.590550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   Y Y Y N N N N N 
2018-06-28 01:50:13.590557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 4:   N N N N N Y Y Y 
2018-06-28 01:50:13.590564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 5:   N N N N Y N Y Y 
2018-06-28 01:50:13.590570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 6:   N N N N Y Y N Y 
2018-06-28 01:50:13.590578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 7:   N N N N Y Y Y N 
2018-06-28 01:50:13.594006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14866 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 7.0)
2018-06-28 01:50:13.769318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14866 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2018-06-28 01:50:13.933752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 14866 MB memory) -> physical GPU (device: 2, name: Tesla V100-PCIE-16GB, pci bus id: 0000:0d:00.0, compute capability: 7.0)
2018-06-28 01:50:14.104232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 14866 MB memory) -> physical GPU (device: 3, name: Tesla V100-PCIE-16GB, pci bus id: 0000:13:00.0, compute capability: 7.0)
2018-06-28 01:50:14.293341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 14866 MB memory) -> physical GPU (device: 4, name: Tesla V100-PCIE-16GB, pci bus id: 0000:83:00.0, compute capability: 7.0)
2018-06-28 01:50:14.464513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 14866 MB memory) -> physical GPU (device: 5, name: Tesla V100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0)
2018-06-28 01:50:14.641829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 14866 MB memory) -> physical GPU (device: 6, name: Tesla V100-PCIE-16GB, pci bus id: 0000:8e:00.0, compute capability: 7.0)
2018-06-28 01:50:14.819418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 14866 MB memory) -> physical GPU (device: 7, name: Tesla V100-PCIE-16GB, pci bus id: 0000:91:00.0, compute capability: 7.0)
>>> Imports:
#coding=utf-8

from __future__ import print_function

try:
    import numpy
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation
except:
    pass

try:
    from keras.models import Sequential
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from keras.utils import to_categorical
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

try:
    from sklearn.model_selection import train_test_split
except:
    pass

try:
    from macros_AWS import scale_x
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'Dense': hp.choice('Dense', [170]+range(202,1001)),
        'Dense_1': hp.choice('Dense_1', range(191,1001)),
        'Dense_2': hp.choice('Dense_2', range(196,1001)),
        'Activation': hp.choice('Activation', ['sigmoid']),
        'optimizer': hp.choice('optimizer', ['adam','nadam']),
        'batch_size': hp.choice('batch_size', [50]+range(300,1001)),
        'epochs': hp.choice('epochs', [2]+range(51,101)),
    }

>>> Data
   1: 
   2: """
   3: Data providing function:
   4: 
   5: This function is separated from create_model() so that hyperopt
   6: won't reload data for each evaluation run.
   7: """
   8: #(x_train, y_train), (x_test, y_test) = mnist.load_data()
   9: #x_train = x_train.reshape(60000, 784)
  10: #x_test = x_test.reshape(10000, 784)
  11: #x_train = x_train.astype('float32')
  12: #x_test = x_test.astype('float32')
  13: #x_train /= 255
  14: #x_test /= 255
  15: #nb_classes = 10
  16: #y_train = np_utils.to_categorical(y_train, nb_classes)
  17: #y_test = np_utils.to_categorical(y_test, nb_classes)
  18: from sklearn.model_selection import train_test_split
  19: from macros_AWS import scale_x
  20: data_directory = '/home/rice/jmc32/Gridsearch_Data/'
  21: data_sample = 'PtRegression_for_DNN_Vars_MODE_15_noBitCompr_RPC_1m_redo.npy'
  22: scaler = 'maxabs'
  23: totalset = numpy.load(data_directory + data_sample)
  24: dataset, testset = train_test_split(totalset, test_size = 0.1)
  25: # Split into input (X) and output (Y) variables
  26: x_train_prescale = dataset[:,1:]
  27: y_train = dataset[:,0]
  28: x_test_prescale = testset[:,1:]
  29: y_test = testset[:,0]
  30: # Scale
  31: print(y_train.shape)
  32: print(y_test.shape)
  33: #print(numpy.matrix(y_train))
  34: x_train, x_test = scale_x(x_train_prescale, x_test_prescale, scaler)
  35: print(x_train.shape)
  36: print(x_test.shape)
  37: #y_train= to_categorical(y_train)
  38: #y_test= to_categorical(y_test)
  39: #x_train= to_categorical(x_train)
  40: #x_test= to_categorical(x_test)
  41: 
  42: 
  43: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     """
   4:     Model providing function:
   5: 
   6:     Create Keras model with double curly brackets dropped-in as needed.
   7:     Return value has to be a valid python dictionary with two customary keys:
   8:         - loss: Specify a numeric evaluation metric to be minimized
   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible
  10:     The last one is optional, though recommended, namely:
  11:         - model: specify the model just created so that we can later use it again.
  12:     """
  13:     model = Sequential()
  14:     model.add(Dense(space['Dense'], input_dim=7))
  15:     model.add(Activation('relu')) 
  16:     model.add(Dense(space['Dense_1']))
  17:     model.add(Activation('relu'))
  18: 
  19:     # If we choose 'four', add an additional fourth layer
  20:     model.add(Dense(space['Dense_2']))
  21: 
  22:         # We can also choose between complete sets of layers
  23:    
  24:     model.add(Activation('relu'))
  25: 
  26:     model.add(Dense(1))
  27:     
  28:     model.add(Activation(space['Activation']))
  29: 
  30: 
  31:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],
  32:                   optimizer=space['optimizer'])
  33: 
  34:     model.fit(x_train, y_train,
  35:               batch_size=space['batch_size'],
  36:               epochs=space['epochs'],
  37:               verbose=2,
  38:               validation_data=(x_test, y_test))
  39:     score, acc = model.evaluate(x_test, y_test, verbose=0)
  40:     print('Test accuracy:', acc)
  41:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}
  42: 
(900000,)
(100000,)
MaxAbs

(900000, 7)
(100000, 7)
Train on 900000 samples, validate on 100000 samples
Epoch 1/51
 - 18s - loss: 0.2112 - acc: 0.9139 - val_loss: 0.1801 - val_acc: 0.9281
Epoch 2/51
 - 7s - loss: 0.1731 - acc: 0.9301 - val_loss: 0.1815 - val_acc: 0.9256
Epoch 3/51
 - 7s - loss: 0.1656 - acc: 0.9327 - val_loss: 0.1716 - val_acc: 0.9308
Epoch 4/51
 - 7s - loss: 0.1621 - acc: 0.9339 - val_loss: 0.1665 - val_acc: 0.9323
Epoch 5/51
 - 7s - loss: 0.1598 - acc: 0.9349 - val_loss: 0.1604 - val_acc: 0.9359
Epoch 6/51
 - 7s - loss: 0.1585 - acc: 0.9354 - val_loss: 0.1621 - val_acc: 0.9347
Epoch 7/51
 - 7s - loss: 0.1570 - acc: 0.9357 - val_loss: 0.1587 - val_acc: 0.9364
Epoch 8/51
 - 7s - loss: 0.1561 - acc: 0.9360 - val_loss: 0.1761 - val_acc: 0.9278
Epoch 9/51
 - 7s - loss: 0.1551 - acc: 0.9366 - val_loss: 0.1582 - val_acc: 0.9364
Epoch 10/51
 - 7s - loss: 0.1540 - acc: 0.9370 - val_loss: 0.1587 - val_acc: 0.9363
Epoch 11/51
 - 7s - loss: 0.1538 - acc: 0.9370 - val_loss: 0.1576 - val_acc: 0.9357
Epoch 12/51
 - 7s - loss: 0.1531 - acc: 0.9372 - val_loss: 0.1552 - val_acc: 0.9380
Epoch 13/51
 - 7s - loss: 0.1526 - acc: 0.9373 - val_loss: 0.1537 - val_acc: 0.9382
Epoch 14/51
 - 7s - loss: 0.1517 - acc: 0.9375 - val_loss: 0.1556 - val_acc: 0.9368
Epoch 15/51
 - 7s - loss: 0.1512 - acc: 0.9378 - val_loss: 0.1532 - val_acc: 0.9384
Epoch 16/51
 - 7s - loss: 0.1510 - acc: 0.9380 - val_loss: 0.1531 - val_acc: 0.9381
Epoch 17/51
 - 7s - loss: 0.1505 - acc: 0.9382 - val_loss: 0.1547 - val_acc: 0.9375
Epoch 18/51
 - 7s - loss: 0.1502 - acc: 0.9382 - val_loss: 0.1524 - val_acc: 0.9391
Epoch 19/51
 - 7s - loss: 0.1498 - acc: 0.9382 - val_loss: 0.1550 - val_acc: 0.9370
Epoch 20/51
 - 7s - loss: 0.1493 - acc: 0.9385 - val_loss: 0.1524 - val_acc: 0.9384
Epoch 21/51
 - 7s - loss: 0.1491 - acc: 0.9384 - val_loss: 0.1549 - val_acc: 0.9368
Epoch 22/51
 - 7s - loss: 0.1488 - acc: 0.9385 - val_loss: 0.1607 - val_acc: 0.9339
Epoch 23/51
 - 7s - loss: 0.1481 - acc: 0.9390 - val_loss: 0.1545 - val_acc: 0.9370
Epoch 24/51
 - 7s - loss: 0.1480 - acc: 0.9390 - val_loss: 0.1526 - val_acc: 0.9387
Epoch 25/51
 - 7s - loss: 0.1477 - acc: 0.9389 - val_loss: 0.1536 - val_acc: 0.9377
Epoch 26/51
 - 7s - loss: 0.1474 - acc: 0.9392 - val_loss: 0.1556 - val_acc: 0.9369
Epoch 27/51
 - 7s - loss: 0.1470 - acc: 0.9393 - val_loss: 0.1539 - val_acc: 0.9384
Epoch 28/51
 - 7s - loss: 0.1469 - acc: 0.9393 - val_loss: 0.1511 - val_acc: 0.9391
Epoch 29/51
 - 7s - loss: 0.1464 - acc: 0.9395 - val_loss: 0.1549 - val_acc: 0.9372
Epoch 30/51
 - 7s - loss: 0.1463 - acc: 0.9393 - val_loss: 0.1530 - val_acc: 0.9388
Epoch 31/51
 - 7s - loss: 0.1459 - acc: 0.9397 - val_loss: 0.1538 - val_acc: 0.9382
Epoch 32/51
 - 7s - loss: 0.1456 - acc: 0.9396 - val_loss: 0.1537 - val_acc: 0.9378
Epoch 33/51
 - 7s - loss: 0.1451 - acc: 0.9399 - val_loss: 0.1535 - val_acc: 0.9381
Epoch 34/51
 - 7s - loss: 0.1449 - acc: 0.9400 - val_loss: 0.1522 - val_acc: 0.9395
Epoch 35/51
 - 7s - loss: 0.1446 - acc: 0.9401 - val_loss: 0.1526 - val_acc: 0.9383
Epoch 36/51
 - 7s - loss: 0.1444 - acc: 0.9402 - val_loss: 0.1556 - val_acc: 0.9368
Epoch 37/51
 - 7s - loss: 0.1439 - acc: 0.9403 - val_loss: 0.1535 - val_acc: 0.9385
Epoch 38/51
 - 7s - loss: 0.1439 - acc: 0.9402 - val_loss: 0.1560 - val_acc: 0.9370
Epoch 39/51
 - 7s - loss: 0.1435 - acc: 0.9403 - val_loss: 0.1569 - val_acc: 0.9370
Epoch 40/51
 - 7s - loss: 0.1432 - acc: 0.9406 - val_loss: 0.1527 - val_acc: 0.9391
Epoch 41/51
 - 7s - loss: 0.1428 - acc: 0.9406 - val_loss: 0.1554 - val_acc: 0.9376
Epoch 42/51
 - 7s - loss: 0.1426 - acc: 0.9407 - val_loss: 0.1535 - val_acc: 0.9386
Epoch 43/51
 - 7s - loss: 0.1422 - acc: 0.9408 - val_loss: 0.1591 - val_acc: 0.9355
Epoch 44/51
 - 7s - loss: 0.1420 - acc: 0.9409 - val_loss: 0.1540 - val_acc: 0.9384
Epoch 45/51
 - 7s - loss: 0.1417 - acc: 0.9411 - val_loss: 0.1563 - val_acc: 0.9373
Epoch 46/51
 - 7s - loss: 0.1416 - acc: 0.9411 - val_loss: 0.1545 - val_acc: 0.9383
Epoch 47/51
 - 7s - loss: 0.1411 - acc: 0.9411 - val_loss: 0.1547 - val_acc: 0.9384
Epoch 48/51
 - 7s - loss: 0.1410 - acc: 0.9415 - val_loss: 0.1552 - val_acc: 0.9379
Epoch 49/51
 - 7s - loss: 0.1406 - acc: 0.9414 - val_loss: 0.1559 - val_acc: 0.9380
Epoch 50/51
 - 7s - loss: 0.1402 - acc: 0.9416 - val_loss: 0.1565 - val_acc: 0.9371
Epoch 51/51
 - 7s - loss: 0.1401 - acc: 0.9416 - val_loss: 0.1562 - val_acc: 0.9376
Test accuracy: 0.93759
Train on 900000 samples, validate on 100000 samples
Epoch 1/88
 - 7s - loss: 0.2109 - acc: 0.9138 - val_loss: 0.1848 - val_acc: 0.9249
Epoch 2/88
 - 7s - loss: 0.1738 - acc: 0.9300 - val_loss: 0.1737 - val_acc: 0.9313
Epoch 3/88
 - 7s - loss: 0.1663 - acc: 0.9329 - val_loss: 0.1653 - val_acc: 0.9342
Epoch 4/88
 - 7s - loss: 0.1626 - acc: 0.9338 - val_loss: 0.1607 - val_acc: 0.9361
Epoch 5/88
 - 7s - loss: 0.1604 - acc: 0.9346 - val_loss: 0.1582 - val_acc: 0.9369
Epoch 6/88
 - 7s - loss: 0.1591 - acc: 0.9348 - val_loss: 0.1622 - val_acc: 0.9360
Epoch 7/88
 - 7s - loss: 0.1577 - acc: 0.9357 - val_loss: 0.1582 - val_acc: 0.9369
Epoch 8/88
 - 7s - loss: 0.1565 - acc: 0.9361 - val_loss: 0.1628 - val_acc: 0.9341
Epoch 9/88
 - 7s - loss: 0.1557 - acc: 0.9361 - val_loss: 0.1667 - val_acc: 0.9320
Epoch 10/88
 - 7s - loss: 0.1550 - acc: 0.9365 - val_loss: 0.1753 - val_acc: 0.9276
Epoch 11/88
 - 7s - loss: 0.1542 - acc: 0.9368 - val_loss: 0.1571 - val_acc: 0.9362
Epoch 12/88
 - 7s - loss: 0.1534 - acc: 0.9370 - val_loss: 0.1578 - val_acc: 0.9364
Epoch 13/88
 - 7s - loss: 0.1527 - acc: 0.9374 - val_loss: 0.1559 - val_acc: 0.9368
Epoch 14/88
 - 7s - loss: 0.1525 - acc: 0.9374 - val_loss: 0.1567 - val_acc: 0.9367
Epoch 15/88
 - 7s - loss: 0.1517 - acc: 0.9377 - val_loss: 0.1555 - val_acc: 0.9366
Epoch 16/88
 - 7s - loss: 0.1515 - acc: 0.9376 - val_loss: 0.1561 - val_acc: 0.9369
Epoch 17/88
 - 7s - loss: 0.1511 - acc: 0.9379 - val_loss: 0.1547 - val_acc: 0.9369
Epoch 18/88
 - 7s - loss: 0.1508 - acc: 0.9380 - val_loss: 0.1547 - val_acc: 0.9374
Epoch 19/88
 - 7s - loss: 0.1502 - acc: 0.9383 - val_loss: 0.1541 - val_acc: 0.9376
Epoch 20/88
 - 7s - loss: 0.1501 - acc: 0.9382 - val_loss: 0.1563 - val_acc: 0.9366
Epoch 21/88
 - 7s - loss: 0.1498 - acc: 0.9382 - val_loss: 0.1557 - val_acc: 0.9368
Epoch 22/88
 - 7s - loss: 0.1492 - acc: 0.9386 - val_loss: 0.1532 - val_acc: 0.9382
Epoch 23/88
 - 7s - loss: 0.1492 - acc: 0.9385 - val_loss: 0.1629 - val_acc: 0.9330
Epoch 24/88
 - 7s - loss: 0.1487 - acc: 0.9388 - val_loss: 0.1640 - val_acc: 0.9327
Epoch 25/88
 - 7s - loss: 0.1485 - acc: 0.9388 - val_loss: 0.1550 - val_acc: 0.9375
Epoch 26/88
 - 7s - loss: 0.1481 - acc: 0.9389 - val_loss: 0.1540 - val_acc: 0.9375
Epoch 27/88
 - 7s - loss: 0.1478 - acc: 0.9390 - val_loss: 0.1557 - val_acc: 0.9366
Epoch 28/88
 - 7s - loss: 0.1475 - acc: 0.9390 - val_loss: 0.1604 - val_acc: 0.9348
Epoch 29/88
 - 7s - loss: 0.1472 - acc: 0.9391 - val_loss: 0.1558 - val_acc: 0.9368
Epoch 30/88
 - 7s - loss: 0.1470 - acc: 0.9392 - val_loss: 0.1531 - val_acc: 0.9375
Epoch 31/88
 - 7s - loss: 0.1470 - acc: 0.9393 - val_loss: 0.1630 - val_acc: 0.9333
Epoch 32/88
 - 7s - loss: 0.1465 - acc: 0.9394 - val_loss: 0.1556 - val_acc: 0.9365
Epoch 33/88
 - 7s - loss: 0.1462 - acc: 0.9393 - val_loss: 0.1536 - val_acc: 0.9379
Epoch 34/88
 - 7s - loss: 0.1459 - acc: 0.9396 - val_loss: 0.1528 - val_acc: 0.9387
Epoch 35/88
 - 7s - loss: 0.1458 - acc: 0.9397 - val_loss: 0.1585 - val_acc: 0.9351
Epoch 36/88
 - 7s - loss: 0.1455 - acc: 0.9397 - val_loss: 0.1503 - val_acc: 0.9399
Epoch 37/88
 - 7s - loss: 0.1452 - acc: 0.9398 - val_loss: 0.1518 - val_acc: 0.9391
Epoch 38/88
 - 7s - loss: 0.1452 - acc: 0.9397 - val_loss: 0.1529 - val_acc: 0.9389
Epoch 39/88
 - 7s - loss: 0.1447 - acc: 0.9400 - val_loss: 0.1540 - val_acc: 0.9380
Epoch 40/88
 - 7s - loss: 0.1443 - acc: 0.9403 - val_loss: 0.1543 - val_acc: 0.9374
Epoch 41/88
 - 7s - loss: 0.1442 - acc: 0.9402 - val_loss: 0.1536 - val_acc: 0.9381
Epoch 42/88
 - 7s - loss: 0.1441 - acc: 0.9403 - val_loss: 0.1540 - val_acc: 0.9384
Epoch 43/88
 - 7s - loss: 0.1438 - acc: 0.9404 - val_loss: 0.1625 - val_acc: 0.9330
Epoch 44/88
 - 7s - loss: 0.1438 - acc: 0.9405 - val_loss: 0.1667 - val_acc: 0.9311
Epoch 45/88
 - 7s - loss: 0.1434 - acc: 0.9404 - val_loss: 0.1520 - val_acc: 0.9388
Epoch 46/88
 - 7s - loss: 0.1429 - acc: 0.9408 - val_loss: 0.1553 - val_acc: 0.9378
Epoch 47/88
 - 7s - loss: 0.1427 - acc: 0.9408 - val_loss: 0.1561 - val_acc: 0.9369
Epoch 48/88
 - 7s - loss: 0.1426 - acc: 0.9407 - val_loss: 0.1557 - val_acc: 0.9369
Epoch 49/88
 - 7s - loss: 0.1423 - acc: 0.9409 - val_loss: 0.1607 - val_acc: 0.9352
Epoch 50/88
 - 7s - loss: 0.1422 - acc: 0.9409 - val_loss: 0.1545 - val_acc: 0.9381
Epoch 51/88
 - 7s - loss: 0.1419 - acc: 0.9410 - val_loss: 0.1553 - val_acc: 0.9377
Epoch 52/88
 - 7s - loss: 0.1416 - acc: 0.9413 - val_loss: 0.1561 - val_acc: 0.9371
Epoch 53/88
 - 7s - loss: 0.1414 - acc: 0.9412 - val_loss: 0.1539 - val_acc: 0.9380
Epoch 54/88
 - 7s - loss: 0.1413 - acc: 0.9412 - val_loss: 0.1545 - val_acc: 0.9383
Epoch 55/88
 - 7s - loss: 0.1410 - acc: 0.9413 - val_loss: 0.1657 - val_acc: 0.9330
Epoch 56/88
 - 7s - loss: 0.1408 - acc: 0.9414 - val_loss: 0.1582 - val_acc: 0.9361
Epoch 57/88
 - 7s - loss: 0.1406 - acc: 0.9414 - val_loss: 0.1589 - val_acc: 0.9368
Epoch 58/88
 - 7s - loss: 0.1403 - acc: 0.9417 - val_loss: 0.1545 - val_acc: 0.9379
Epoch 59/88
 - 7s - loss: 0.1400 - acc: 0.9418 - val_loss: 0.1603 - val_acc: 0.9355
Epoch 60/88
 - 7s - loss: 0.1400 - acc: 0.9417 - val_loss: 0.1576 - val_acc: 0.9367
Epoch 61/88
 - 7s - loss: 0.1396 - acc: 0.9419 - val_loss: 0.1555 - val_acc: 0.9378
Epoch 62/88
 - 7s - loss: 0.1394 - acc: 0.9419 - val_loss: 0.1562 - val_acc: 0.9382
Epoch 63/88
 - 7s - loss: 0.1394 - acc: 0.9419 - val_loss: 0.1585 - val_acc: 0.9368
Epoch 64/88
 - 7s - loss: 0.1390 - acc: 0.9421 - val_loss: 0.1566 - val_acc: 0.9371
Epoch 65/88
 - 7s - loss: 0.1388 - acc: 0.9423 - val_loss: 0.1639 - val_acc: 0.9339
Epoch 66/88
 - 7s - loss: 0.1385 - acc: 0.9423 - val_loss: 0.1558 - val_acc: 0.9387
Epoch 67/88
 - 7s - loss: 0.1384 - acc: 0.9422 - val_loss: 0.1606 - val_acc: 0.9354
Epoch 68/88
 - 7s - loss: 0.1381 - acc: 0.9424 - val_loss: 0.1577 - val_acc: 0.9373
Epoch 69/88
 - 7s - loss: 0.1379 - acc: 0.9426 - val_loss: 0.1570 - val_acc: 0.9381
Epoch 70/88
 - 7s - loss: 0.1377 - acc: 0.9424 - val_loss: 0.1565 - val_acc: 0.9381
Epoch 71/88
 - 7s - loss: 0.1374 - acc: 0.9426 - val_loss: 0.1596 - val_acc: 0.9367
Epoch 72/88
 - 7s - loss: 0.1373 - acc: 0.9427 - val_loss: 0.1594 - val_acc: 0.9374
Epoch 73/88
 - 7s - loss: 0.1371 - acc: 0.9428 - val_loss: 0.1565 - val_acc: 0.9384
Epoch 74/88
 - 7s - loss: 0.1369 - acc: 0.9429 - val_loss: 0.1602 - val_acc: 0.9375
Epoch 75/88
 - 7s - loss: 0.1365 - acc: 0.9430 - val_loss: 0.1576 - val_acc: 0.9378
Epoch 76/88
 - 7s - loss: 0.1366 - acc: 0.9429 - val_loss: 0.1628 - val_acc: 0.9355
Epoch 77/88
 - 7s - loss: 0.1364 - acc: 0.9431 - val_loss: 0.1681 - val_acc: 0.9332
Epoch 78/88
 - 7s - loss: 0.1361 - acc: 0.9432 - val_loss: 0.1603 - val_acc: 0.9377
Epoch 79/88
 - 7s - loss: 0.1358 - acc: 0.9431 - val_loss: 0.1637 - val_acc: 0.9358
Epoch 80/88
 - 7s - loss: 0.1356 - acc: 0.9433 - val_loss: 0.1636 - val_acc: 0.9348
Epoch 81/88
 - 7s - loss: 0.1354 - acc: 0.9433 - val_loss: 0.1615 - val_acc: 0.9368
Epoch 82/88
 - 7s - loss: 0.1351 - acc: 0.9435 - val_loss: 0.1583 - val_acc: 0.9380
Epoch 83/88
 - 7s - loss: 0.1352 - acc: 0.9435 - val_loss: 0.1621 - val_acc: 0.9363
Epoch 84/88
 - 7s - loss: 0.1348 - acc: 0.9436 - val_loss: 0.1613 - val_acc: 0.9372
Epoch 85/88
 - 7s - loss: 0.1346 - acc: 0.9438 - val_loss: 0.1659 - val_acc: 0.9354
Epoch 86/88
 - 7s - loss: 0.1344 - acc: 0.9438 - val_loss: 0.1648 - val_acc: 0.9360
Epoch 87/88
 - 7s - loss: 0.1344 - acc: 0.9437 - val_loss: 0.1645 - val_acc: 0.9363
Epoch 88/88
 - 7s - loss: 0.1340 - acc: 0.9439 - val_loss: 0.1631 - val_acc: 0.9358
Test accuracy: 0.93579
Train on 900000 samples, validate on 100000 samples
Epoch 1/84
 - 6s - loss: 0.2212 - acc: 0.9089 - val_loss: 0.1890 - val_acc: 0.9241
Epoch 2/84
 - 5s - loss: 0.1687 - acc: 0.9318 - val_loss: 0.1652 - val_acc: 0.9336
Epoch 3/84
 - 6s - loss: 0.1618 - acc: 0.9341 - val_loss: 0.1620 - val_acc: 0.9357
Epoch 4/84
 - 6s - loss: 0.1591 - acc: 0.9351 - val_loss: 0.1571 - val_acc: 0.9374
Epoch 5/84
 - 6s - loss: 0.1572 - acc: 0.9358 - val_loss: 0.1599 - val_acc: 0.9357
Epoch 6/84
 - 6s - loss: 0.1560 - acc: 0.9361 - val_loss: 0.1584 - val_acc: 0.9355
Epoch 7/84
 - 6s - loss: 0.1550 - acc: 0.9364 - val_loss: 0.1597 - val_acc: 0.9354
Epoch 8/84
 - 6s - loss: 0.1541 - acc: 0.9369 - val_loss: 0.1544 - val_acc: 0.9383
Epoch 9/84
 - 6s - loss: 0.1533 - acc: 0.9373 - val_loss: 0.1545 - val_acc: 0.9380
Epoch 10/84
 - 6s - loss: 0.1528 - acc: 0.9372 - val_loss: 0.1554 - val_acc: 0.9374
Epoch 11/84
 - 6s - loss: 0.1522 - acc: 0.9374 - val_loss: 0.1558 - val_acc: 0.9370
Epoch 12/84
 - 6s - loss: 0.1516 - acc: 0.9377 - val_loss: 0.1547 - val_acc: 0.9373
Epoch 13/84
 - 6s - loss: 0.1513 - acc: 0.9379 - val_loss: 0.1633 - val_acc: 0.9335
Epoch 14/84
 - 6s - loss: 0.1510 - acc: 0.9379 - val_loss: 0.1590 - val_acc: 0.9354
Epoch 15/84
 - 6s - loss: 0.1505 - acc: 0.9381 - val_loss: 0.1586 - val_acc: 0.9353
Epoch 16/84
 - 6s - loss: 0.1500 - acc: 0.9380 - val_loss: 0.1549 - val_acc: 0.9374
Epoch 17/84
 - 6s - loss: 0.1497 - acc: 0.9384 - val_loss: 0.1529 - val_acc: 0.9382
Epoch 18/84
 - 6s - loss: 0.1493 - acc: 0.9385 - val_loss: 0.1538 - val_acc: 0.9377
Epoch 19/84
 - 6s - loss: 0.1491 - acc: 0.9385 - val_loss: 0.1537 - val_acc: 0.9382
Epoch 20/84
 - 6s - loss: 0.1486 - acc: 0.9386 - val_loss: 0.1563 - val_acc: 0.9368
Epoch 21/84
 - 6s - loss: 0.1485 - acc: 0.9387 - val_loss: 0.1530 - val_acc: 0.9388
Epoch 22/84
 - 6s - loss: 0.1481 - acc: 0.9388 - val_loss: 0.1548 - val_acc: 0.9372
Epoch 23/84
 - 6s - loss: 0.1478 - acc: 0.9389 - val_loss: 0.1587 - val_acc: 0.9358
Epoch 24/84
 - 6s - loss: 0.1475 - acc: 0.9391 - val_loss: 0.1559 - val_acc: 0.9373
Epoch 25/84
 - 6s - loss: 0.1473 - acc: 0.9392 - val_loss: 0.1538 - val_acc: 0.9385
Epoch 26/84
 - 6s - loss: 0.1469 - acc: 0.9394 - val_loss: 0.1533 - val_acc: 0.9386
Epoch 27/84
 - 6s - loss: 0.1466 - acc: 0.9396 - val_loss: 0.1586 - val_acc: 0.9353
Epoch 28/84
 - 6s - loss: 0.1463 - acc: 0.9395 - val_loss: 0.1622 - val_acc: 0.9344
Epoch 29/84
 - 6s - loss: 0.1461 - acc: 0.9396 - val_loss: 0.1542 - val_acc: 0.9377
Epoch 30/84
 - 6s - loss: 0.1458 - acc: 0.9398 - val_loss: 0.1555 - val_acc: 0.9375
Epoch 31/84
 - 6s - loss: 0.1455 - acc: 0.9398 - val_loss: 0.1548 - val_acc: 0.9387
Epoch 32/84
 - 6s - loss: 0.1452 - acc: 0.9400 - val_loss: 0.1561 - val_acc: 0.9374
Epoch 33/84
 - 6s - loss: 0.1450 - acc: 0.9401 - val_loss: 0.1562 - val_acc: 0.9366
Epoch 34/84
 - 6s - loss: 0.1448 - acc: 0.9400 - val_loss: 0.1559 - val_acc: 0.9365
Epoch 35/84
 - 6s - loss: 0.1444 - acc: 0.9403 - val_loss: 0.1586 - val_acc: 0.9359
Epoch 36/84
 - 6s - loss: 0.1443 - acc: 0.9401 - val_loss: 0.1541 - val_acc: 0.9386
Epoch 37/84
 - 6s - loss: 0.1440 - acc: 0.9404 - val_loss: 0.1536 - val_acc: 0.9385
Epoch 38/84
 - 6s - loss: 0.1438 - acc: 0.9403 - val_loss: 0.1564 - val_acc: 0.9367
Epoch 39/84
 - 6s - loss: 0.1435 - acc: 0.9405 - val_loss: 0.1620 - val_acc: 0.9346
Epoch 40/84
 - 6s - loss: 0.1432 - acc: 0.9406 - val_loss: 0.1566 - val_acc: 0.9365
Epoch 41/84
 - 6s - loss: 0.1430 - acc: 0.9408 - val_loss: 0.1557 - val_acc: 0.9374
Epoch 42/84
 - 6s - loss: 0.1427 - acc: 0.9409 - val_loss: 0.1555 - val_acc: 0.9378
Epoch 43/84
 - 6s - loss: 0.1424 - acc: 0.9409 - val_loss: 0.1544 - val_acc: 0.9378
Epoch 44/84
 - 6s - loss: 0.1422 - acc: 0.9409 - val_loss: 0.1563 - val_acc: 0.9376
Epoch 45/84
 - 6s - loss: 0.1420 - acc: 0.9411 - val_loss: 0.1567 - val_acc: 0.9369
Epoch 46/84
 - 6s - loss: 0.1416 - acc: 0.9413 - val_loss: 0.1526 - val_acc: 0.9393
Epoch 47/84
 - 6s - loss: 0.1414 - acc: 0.9414 - val_loss: 0.1570 - val_acc: 0.9372
Epoch 48/84
 - 6s - loss: 0.1411 - acc: 0.9412 - val_loss: 0.1546 - val_acc: 0.9386
Epoch 49/84
 - 6s - loss: 0.1409 - acc: 0.9414 - val_loss: 0.1574 - val_acc: 0.9366
Epoch 50/84
 - 6s - loss: 0.1406 - acc: 0.9416 - val_loss: 0.1549 - val_acc: 0.9382
Epoch 51/84
 - 6s - loss: 0.1405 - acc: 0.9416 - val_loss: 0.1566 - val_acc: 0.9376
Epoch 52/84
 - 6s - loss: 0.1403 - acc: 0.9418 - val_loss: 0.1567 - val_acc: 0.9384
Epoch 53/84
 - 6s - loss: 0.1400 - acc: 0.9418 - val_loss: 0.1567 - val_acc: 0.9382
Epoch 54/84
 - 6s - loss: 0.1397 - acc: 0.9420 - val_loss: 0.1584 - val_acc: 0.9365
Epoch 55/84
 - 6s - loss: 0.1395 - acc: 0.9418 - val_loss: 0.1566 - val_acc: 0.9377
Epoch 56/84
 - 6s - loss: 0.1392 - acc: 0.9420 - val_loss: 0.1578 - val_acc: 0.9376
Epoch 57/84
 - 6s - loss: 0.1390 - acc: 0.9420 - val_loss: 0.1585 - val_acc: 0.9364
Epoch 58/84
 - 6s - loss: 0.1387 - acc: 0.9422 - val_loss: 0.1589 - val_acc: 0.9373
Epoch 59/84
 - 6s - loss: 0.1384 - acc: 0.9424 - val_loss: 0.1626 - val_acc: 0.9357
Epoch 60/84
 - 6s - loss: 0.1383 - acc: 0.9423 - val_loss: 0.1594 - val_acc: 0.9374
Epoch 61/84
 - 6s - loss: 0.1380 - acc: 0.9424 - val_loss: 0.1590 - val_acc: 0.9376
Epoch 62/84
 - 6s - loss: 0.1378 - acc: 0.9426 - val_loss: 0.1636 - val_acc: 0.9352
Epoch 63/84
 - 6s - loss: 0.1376 - acc: 0.9426 - val_loss: 0.1596 - val_acc: 0.9370
Epoch 64/84
 - 6s - loss: 0.1374 - acc: 0.9427 - val_loss: 0.1612 - val_acc: 0.9372
Epoch 65/84
 - 6s - loss: 0.1371 - acc: 0.9428 - val_loss: 0.1611 - val_acc: 0.9366
Epoch 66/84
 - 6s - loss: 0.1369 - acc: 0.9429 - val_loss: 0.1611 - val_acc: 0.9364
Epoch 67/84
 - 6s - loss: 0.1365 - acc: 0.9428 - val_loss: 0.1650 - val_acc: 0.9351
Epoch 68/84
 - 6s - loss: 0.1366 - acc: 0.9430 - val_loss: 0.1601 - val_acc: 0.9374
Epoch 69/84
 - 6s - loss: 0.1363 - acc: 0.9430 - val_loss: 0.1595 - val_acc: 0.9373
Epoch 70/84
 - 6s - loss: 0.1361 - acc: 0.9432 - val_loss: 0.1607 - val_acc: 0.9370
Epoch 71/84
 - 6s - loss: 0.1358 - acc: 0.9433 - val_loss: 0.1604 - val_acc: 0.9377
Epoch 72/84
 - 6s - loss: 0.1356 - acc: 0.9434 - val_loss: 0.1652 - val_acc: 0.9362
Epoch 73/84
 - 6s - loss: 0.1355 - acc: 0.9436 - val_loss: 0.1632 - val_acc: 0.9363
Epoch 74/84
 - 6s - loss: 0.1354 - acc: 0.9434 - val_loss: 0.1623 - val_acc: 0.9376
Epoch 75/84
 - 6s - loss: 0.1351 - acc: 0.9435 - val_loss: 0.1648 - val_acc: 0.9364
Epoch 76/84
 - 6s - loss: 0.1348 - acc: 0.9438 - val_loss: 0.1630 - val_acc: 0.9364
Epoch 77/84
 - 6s - loss: 0.1344 - acc: 0.9438 - val_loss: 0.1699 - val_acc: 0.9341
Epoch 78/84
 - 6s - loss: 0.1343 - acc: 0.9438 - val_loss: 0.1641 - val_acc: 0.9362
Epoch 79/84
 - 6s - loss: 0.1341 - acc: 0.9438 - val_loss: 0.1644 - val_acc: 0.9362
Epoch 80/84
 - 6s - loss: 0.1338 - acc: 0.9441 - val_loss: 0.1665 - val_acc: 0.9354
Epoch 81/84
 - 6s - loss: 0.1337 - acc: 0.9440 - val_loss: 0.1661 - val_acc: 0.9357
Epoch 82/84
 - 6s - loss: 0.1336 - acc: 0.9442 - val_loss: 0.1623 - val_acc: 0.9373
Epoch 83/84
 - 6s - loss: 0.1334 - acc: 0.9442 - val_loss: 0.1654 - val_acc: 0.9367
Epoch 84/84
 - 6s - loss: 0.1331 - acc: 0.9443 - val_loss: 0.1706 - val_acc: 0.9342
Test accuracy: 0.93419
Train on 900000 samples, validate on 100000 samples
Epoch 1/87
 - 9s - loss: 0.2090 - acc: 0.9135 - val_loss: 0.1688 - val_acc: 0.9334
Epoch 2/87
 - 8s - loss: 0.1665 - acc: 0.9324 - val_loss: 0.1661 - val_acc: 0.9335
Epoch 3/87
 - 8s - loss: 0.1610 - acc: 0.9343 - val_loss: 0.1636 - val_acc: 0.9339
Epoch 4/87
 - 8s - loss: 0.1585 - acc: 0.9351 - val_loss: 0.1613 - val_acc: 0.9357
Epoch 5/87
 - 8s - loss: 0.1568 - acc: 0.9358 - val_loss: 0.1601 - val_acc: 0.9353
Epoch 6/87
 - 8s - loss: 0.1556 - acc: 0.9364 - val_loss: 0.1602 - val_acc: 0.9356
Epoch 7/87
 - 8s - loss: 0.1548 - acc: 0.9367 - val_loss: 0.1590 - val_acc: 0.9361
Epoch 8/87
 - 8s - loss: 0.1538 - acc: 0.9370 - val_loss: 0.1554 - val_acc: 0.9373
Epoch 9/87
 - 8s - loss: 0.1533 - acc: 0.9370 - val_loss: 0.1541 - val_acc: 0.9383
Epoch 10/87
 - 8s - loss: 0.1527 - acc: 0.9374 - val_loss: 0.1547 - val_acc: 0.9381
Epoch 11/87
 - 8s - loss: 0.1522 - acc: 0.9374 - val_loss: 0.1551 - val_acc: 0.9376
Epoch 12/87
 - 8s - loss: 0.1518 - acc: 0.9377 - val_loss: 0.1562 - val_acc: 0.9374
Epoch 13/87
 - 8s - loss: 0.1513 - acc: 0.9377 - val_loss: 0.1589 - val_acc: 0.9357
Epoch 14/87
 - 8s - loss: 0.1510 - acc: 0.9379 - val_loss: 0.1580 - val_acc: 0.9363
Epoch 15/87
 - 8s - loss: 0.1505 - acc: 0.9380 - val_loss: 0.1628 - val_acc: 0.9343
Epoch 16/87
 - 8s - loss: 0.1502 - acc: 0.9381 - val_loss: 0.1579 - val_acc: 0.9353
Epoch 17/87
 - 8s - loss: 0.1499 - acc: 0.9382 - val_loss: 0.1546 - val_acc: 0.9375
Epoch 18/87
 - 8s - loss: 0.1495 - acc: 0.9384 - val_loss: 0.1530 - val_acc: 0.9386
Epoch 19/87
 - 8s - loss: 0.1492 - acc: 0.9384 - val_loss: 0.1552 - val_acc: 0.9370
Epoch 20/87
 - 8s - loss: 0.1487 - acc: 0.9385 - val_loss: 0.1552 - val_acc: 0.9370
Epoch 21/87
 - 8s - loss: 0.1484 - acc: 0.9387 - val_loss: 0.1575 - val_acc: 0.9372
Epoch 22/87
 - 8s - loss: 0.1482 - acc: 0.9387 - val_loss: 0.1540 - val_acc: 0.9383
Epoch 23/87
 - 8s - loss: 0.1479 - acc: 0.9390 - val_loss: 0.1596 - val_acc: 0.9356
Epoch 24/87
 - 8s - loss: 0.1476 - acc: 0.9388 - val_loss: 0.1515 - val_acc: 0.9388
Epoch 25/87
 - 8s - loss: 0.1474 - acc: 0.9391 - val_loss: 0.1556 - val_acc: 0.9374
Epoch 26/87
 - 8s - loss: 0.1472 - acc: 0.9392 - val_loss: 0.1568 - val_acc: 0.9363
Epoch 27/87
 - 8s - loss: 0.1468 - acc: 0.9395 - val_loss: 0.1594 - val_acc: 0.9363
Epoch 28/87
 - 8s - loss: 0.1466 - acc: 0.9393 - val_loss: 0.1530 - val_acc: 0.9384
Epoch 29/87
 - 8s - loss: 0.1465 - acc: 0.9395 - val_loss: 0.1529 - val_acc: 0.9385
Epoch 30/87
 - 8s - loss: 0.1461 - acc: 0.9396 - val_loss: 0.1548 - val_acc: 0.9380
Epoch 31/87
 - 8s - loss: 0.1458 - acc: 0.9397 - val_loss: 0.1559 - val_acc: 0.9382
Epoch 32/87
 - 8s - loss: 0.1455 - acc: 0.9398 - val_loss: 0.1554 - val_acc: 0.9372
Epoch 33/87
 - 8s - loss: 0.1453 - acc: 0.9399 - val_loss: 0.1565 - val_acc: 0.9363
Epoch 34/87
 - 8s - loss: 0.1450 - acc: 0.9401 - val_loss: 0.1560 - val_acc: 0.9372
Epoch 35/87
 - 8s - loss: 0.1447 - acc: 0.9400 - val_loss: 0.1538 - val_acc: 0.9385
Epoch 36/87
 - 8s - loss: 0.1446 - acc: 0.9400 - val_loss: 0.1561 - val_acc: 0.9369
Epoch 37/87
 - 8s - loss: 0.1446 - acc: 0.9400 - val_loss: 0.1554 - val_acc: 0.9384
Epoch 38/87
 - 8s - loss: 0.1441 - acc: 0.9403 - val_loss: 0.1529 - val_acc: 0.9388
Epoch 39/87
 - 8s - loss: 0.1439 - acc: 0.9403 - val_loss: 0.1535 - val_acc: 0.9386
Epoch 40/87
 - 8s - loss: 0.1437 - acc: 0.9404 - val_loss: 0.1566 - val_acc: 0.9375
Epoch 41/87
 - 8s - loss: 0.1435 - acc: 0.9404 - val_loss: 0.1532 - val_acc: 0.9387
Epoch 42/87
 - 8s - loss: 0.1432 - acc: 0.9406 - val_loss: 0.1540 - val_acc: 0.9389
Epoch 43/87
 - 8s - loss: 0.1431 - acc: 0.9407 - val_loss: 0.1552 - val_acc: 0.9380
Epoch 44/87
 - 8s - loss: 0.1429 - acc: 0.9406 - val_loss: 0.1584 - val_acc: 0.9358
Epoch 45/87
 - 8s - loss: 0.1427 - acc: 0.9409 - val_loss: 0.1550 - val_acc: 0.9378
Epoch 46/87
 - 8s - loss: 0.1425 - acc: 0.9407 - val_loss: 0.1638 - val_acc: 0.9337
Epoch 47/87
 - 8s - loss: 0.1423 - acc: 0.9408 - val_loss: 0.1542 - val_acc: 0.9391
Epoch 48/87
 - 8s - loss: 0.1420 - acc: 0.9410 - val_loss: 0.1580 - val_acc: 0.9361
Epoch 49/87
 - 8s - loss: 0.1418 - acc: 0.9409 - val_loss: 0.1568 - val_acc: 0.9384
Epoch 50/87
 - 8s - loss: 0.1418 - acc: 0.9411 - val_loss: 0.1569 - val_acc: 0.9383
Epoch 51/87
 - 8s - loss: 0.1413 - acc: 0.9412 - val_loss: 0.1631 - val_acc: 0.9347
Epoch 52/87
 - 8s - loss: 0.1414 - acc: 0.9412 - val_loss: 0.1586 - val_acc: 0.9371
Epoch 53/87
 - 8s - loss: 0.1411 - acc: 0.9413 - val_loss: 0.1596 - val_acc: 0.9366
Epoch 54/87
 - 8s - loss: 0.1407 - acc: 0.9415 - val_loss: 0.1549 - val_acc: 0.9386
Epoch 55/87
 - 8s - loss: 0.1408 - acc: 0.9413 - val_loss: 0.1576 - val_acc: 0.9374
Epoch 56/87
 - 8s - loss: 0.1405 - acc: 0.9416 - val_loss: 0.1592 - val_acc: 0.9366
Epoch 57/87
 - 8s - loss: 0.1401 - acc: 0.9418 - val_loss: 0.1609 - val_acc: 0.9368
Epoch 58/87
 - 8s - loss: 0.1401 - acc: 0.9418 - val_loss: 0.1608 - val_acc: 0.9373
Epoch 59/87
 - 8s - loss: 0.1399 - acc: 0.9418 - val_loss: 0.1576 - val_acc: 0.9380
Epoch 60/87
 - 9s - loss: 0.1398 - acc: 0.9417 - val_loss: 0.1569 - val_acc: 0.9378
Epoch 61/87
 - 8s - loss: 0.1396 - acc: 0.9417 - val_loss: 0.1616 - val_acc: 0.9362
Epoch 62/87
 - 8s - loss: 0.1394 - acc: 0.9418 - val_loss: 0.1578 - val_acc: 0.9380
Epoch 63/87
 - 8s - loss: 0.1392 - acc: 0.9420 - val_loss: 0.1657 - val_acc: 0.9336
Epoch 64/87
 - 9s - loss: 0.1390 - acc: 0.9421 - val_loss: 0.1587 - val_acc: 0.9380
Epoch 65/87
 - 8s - loss: 0.1388 - acc: 0.9423 - val_loss: 0.1595 - val_acc: 0.9380
Epoch 66/87
 - 8s - loss: 0.1387 - acc: 0.9422 - val_loss: 0.1584 - val_acc: 0.9389
Epoch 67/87
 - 8s - loss: 0.1383 - acc: 0.9422 - val_loss: 0.1588 - val_acc: 0.9371
Epoch 68/87
 - 8s - loss: 0.1381 - acc: 0.9423 - val_loss: 0.1586 - val_acc: 0.9374
Epoch 69/87
 - 8s - loss: 0.1383 - acc: 0.9423 - val_loss: 0.1608 - val_acc: 0.9369
Epoch 70/87
 - 8s - loss: 0.1381 - acc: 0.9424 - val_loss: 0.1598 - val_acc: 0.9375
Epoch 71/87
 - 8s - loss: 0.1380 - acc: 0.9425 - val_loss: 0.1619 - val_acc: 0.9362
Epoch 72/87
 - 8s - loss: 0.1375 - acc: 0.9424 - val_loss: 0.1610 - val_acc: 0.9365
Epoch 73/87
 - 8s - loss: 0.1376 - acc: 0.9425 - val_loss: 0.1665 - val_acc: 0.9345
Epoch 74/87
 - 8s - loss: 0.1373 - acc: 0.9428 - val_loss: 0.1604 - val_acc: 0.9376
Epoch 75/87
 - 8s - loss: 0.1370 - acc: 0.9427 - val_loss: 0.1597 - val_acc: 0.9382
Epoch 76/87
 - 8s - loss: 0.1370 - acc: 0.9426 - val_loss: 0.1629 - val_acc: 0.9375
Epoch 77/87
 - 8s - loss: 0.1370 - acc: 0.9429 - val_loss: 0.1596 - val_acc: 0.9386
Epoch 78/87
 - 8s - loss: 0.1368 - acc: 0.9428 - val_loss: 0.1634 - val_acc: 0.9369
Epoch 79/87
 - 8s - loss: 0.1366 - acc: 0.9429 - val_loss: 0.1700 - val_acc: 0.9345
Epoch 80/87
 - 8s - loss: 0.1364 - acc: 0.9429 - val_loss: 0.1634 - val_acc: 0.9369
Epoch 81/87
 - 8s - loss: 0.1362 - acc: 0.9431 - val_loss: 0.1615 - val_acc: 0.9379
Epoch 82/87
 - 8s - loss: 0.1362 - acc: 0.9431 - val_loss: 0.1621 - val_acc: 0.9374
Epoch 83/87
 - 8s - loss: 0.1361 - acc: 0.9431 - val_loss: 0.1595 - val_acc: 0.9380
Epoch 84/87
 - 8s - loss: 0.1358 - acc: 0.9433 - val_loss: 0.1663 - val_acc: 0.9361
Epoch 85/87
 - 8s - loss: 0.1359 - acc: 0.9432 - val_loss: 0.1634 - val_acc: 0.9369
Epoch 86/87
 - 8s - loss: 0.1356 - acc: 0.9435 - val_loss: 0.1610 - val_acc: 0.9381
Epoch 87/87
 - 8s - loss: 0.1354 - acc: 0.9434 - val_loss: 0.1635 - val_acc: 0.9372
Test accuracy: 0.9372
Train on 900000 samples, validate on 100000 samples
Epoch 1/94
 - 11s - loss: 0.2050 - acc: 0.9160 - val_loss: 0.1696 - val_acc: 0.9323
Epoch 2/94
 - 10s - loss: 0.1663 - acc: 0.9325 - val_loss: 0.1618 - val_acc: 0.9352
Epoch 3/94
 - 10s - loss: 0.1614 - acc: 0.9343 - val_loss: 0.1729 - val_acc: 0.9289
Epoch 4/94
 - 10s - loss: 0.1590 - acc: 0.9353 - val_loss: 0.1578 - val_acc: 0.9367
Epoch 5/94
 - 10s - loss: 0.1571 - acc: 0.9358 - val_loss: 0.1662 - val_acc: 0.9330
Epoch 6/94
 - 10s - loss: 0.1560 - acc: 0.9363 - val_loss: 0.1629 - val_acc: 0.9339
Epoch 7/94
 - 10s - loss: 0.1551 - acc: 0.9365 - val_loss: 0.1635 - val_acc: 0.9338
Epoch 8/94
 - 10s - loss: 0.1545 - acc: 0.9368 - val_loss: 0.1574 - val_acc: 0.9364
Epoch 9/94
 - 10s - loss: 0.1540 - acc: 0.9368 - val_loss: 0.1591 - val_acc: 0.9357
Epoch 10/94
 - 10s - loss: 0.1534 - acc: 0.9370 - val_loss: 0.1534 - val_acc: 0.9386
Epoch 11/94
 - 11s - loss: 0.1528 - acc: 0.9373 - val_loss: 0.1542 - val_acc: 0.9383
Epoch 12/94
 - 10s - loss: 0.1524 - acc: 0.9374 - val_loss: 0.1597 - val_acc: 0.9350
Epoch 13/94
 - 10s - loss: 0.1519 - acc: 0.9376 - val_loss: 0.1528 - val_acc: 0.9389
Epoch 14/94
 - 10s - loss: 0.1515 - acc: 0.9375 - val_loss: 0.1537 - val_acc: 0.9382
Epoch 15/94
 - 11s - loss: 0.1513 - acc: 0.9378 - val_loss: 0.1553 - val_acc: 0.9370
Epoch 16/94
 - 10s - loss: 0.1509 - acc: 0.9380 - val_loss: 0.1586 - val_acc: 0.9361
Epoch 17/94
 - 10s - loss: 0.1506 - acc: 0.9381 - val_loss: 0.1570 - val_acc: 0.9370
Epoch 18/94
 - 10s - loss: 0.1504 - acc: 0.9380 - val_loss: 0.1636 - val_acc: 0.9332
Epoch 19/94
 - 10s - loss: 0.1500 - acc: 0.9382 - val_loss: 0.1629 - val_acc: 0.9338
Epoch 20/94
 - 10s - loss: 0.1497 - acc: 0.9384 - val_loss: 0.1604 - val_acc: 0.9349
Epoch 21/94
 - 10s - loss: 0.1494 - acc: 0.9385 - val_loss: 0.1584 - val_acc: 0.9355
Epoch 22/94
 - 10s - loss: 0.1491 - acc: 0.9384 - val_loss: 0.1596 - val_acc: 0.9361
Epoch 23/94
 - 10s - loss: 0.1490 - acc: 0.9386 - val_loss: 0.1553 - val_acc: 0.9371
Epoch 24/94
 - 10s - loss: 0.1488 - acc: 0.9388 - val_loss: 0.1568 - val_acc: 0.9366
Epoch 25/94
 - 10s - loss: 0.1486 - acc: 0.9388 - val_loss: 0.1579 - val_acc: 0.9364
Epoch 26/94
 - 10s - loss: 0.1482 - acc: 0.9388 - val_loss: 0.1539 - val_acc: 0.9382
Epoch 27/94
 - 10s - loss: 0.1481 - acc: 0.9389 - val_loss: 0.1572 - val_acc: 0.9360
Epoch 28/94
 - 10s - loss: 0.1479 - acc: 0.9390 - val_loss: 0.1542 - val_acc: 0.9383
Epoch 29/94
 - 10s - loss: 0.1476 - acc: 0.9391 - val_loss: 0.1520 - val_acc: 0.9386
Epoch 30/94
 - 10s - loss: 0.1473 - acc: 0.9391 - val_loss: 0.1596 - val_acc: 0.9359
Epoch 31/94
 - 10s - loss: 0.1471 - acc: 0.9394 - val_loss: 0.1555 - val_acc: 0.9368
Epoch 32/94
 - 10s - loss: 0.1470 - acc: 0.9393 - val_loss: 0.1538 - val_acc: 0.9377
Epoch 33/94
 - 10s - loss: 0.1467 - acc: 0.9393 - val_loss: 0.1559 - val_acc: 0.9371
Epoch 34/94
 - 10s - loss: 0.1466 - acc: 0.9395 - val_loss: 0.1566 - val_acc: 0.9363
Epoch 35/94
 - 10s - loss: 0.1465 - acc: 0.9397 - val_loss: 0.1537 - val_acc: 0.9383
Epoch 36/94
 - 10s - loss: 0.1462 - acc: 0.9394 - val_loss: 0.1609 - val_acc: 0.9347
Epoch 37/94
 - 10s - loss: 0.1460 - acc: 0.9397 - val_loss: 0.1546 - val_acc: 0.9386
Epoch 38/94
 - 10s - loss: 0.1458 - acc: 0.9397 - val_loss: 0.1552 - val_acc: 0.9373
Epoch 39/94
 - 10s - loss: 0.1456 - acc: 0.9398 - val_loss: 0.1547 - val_acc: 0.9376
Epoch 40/94
 - 10s - loss: 0.1456 - acc: 0.9397 - val_loss: 0.1543 - val_acc: 0.9375
Epoch 41/94
 - 10s - loss: 0.1453 - acc: 0.9400 - val_loss: 0.1552 - val_acc: 0.9374
Epoch 42/94
 - 10s - loss: 0.1451 - acc: 0.9400 - val_loss: 0.1564 - val_acc: 0.9374
Epoch 43/94
 - 10s - loss: 0.1450 - acc: 0.9399 - val_loss: 0.1529 - val_acc: 0.9386
Epoch 44/94
 - 10s - loss: 0.1450 - acc: 0.9399 - val_loss: 0.1545 - val_acc: 0.9379
Epoch 45/94
 - 10s - loss: 0.1446 - acc: 0.9401 - val_loss: 0.1579 - val_acc: 0.9364
Epoch 46/94
 - 10s - loss: 0.1444 - acc: 0.9399 - val_loss: 0.1552 - val_acc: 0.9375
Epoch 47/94
 - 10s - loss: 0.1444 - acc: 0.9401 - val_loss: 0.1596 - val_acc: 0.9355
Epoch 48/94
 - 10s - loss: 0.1441 - acc: 0.9403 - val_loss: 0.1559 - val_acc: 0.9373
Epoch 49/94
 - 10s - loss: 0.1440 - acc: 0.9403 - val_loss: 0.1542 - val_acc: 0.9381
Epoch 50/94
 - 10s - loss: 0.1439 - acc: 0.9404 - val_loss: 0.1545 - val_acc: 0.9379
Epoch 51/94
 - 10s - loss: 0.1438 - acc: 0.9405 - val_loss: 0.1550 - val_acc: 0.9378
Epoch 52/94
 - 10s - loss: 0.1436 - acc: 0.9404 - val_loss: 0.1587 - val_acc: 0.9365
Epoch 53/94
 - 10s - loss: 0.1436 - acc: 0.9406 - val_loss: 0.1567 - val_acc: 0.9366
Epoch 54/94
 - 10s - loss: 0.1434 - acc: 0.9405 - val_loss: 0.1540 - val_acc: 0.9379
Epoch 55/94
 - 10s - loss: 0.1433 - acc: 0.9407 - val_loss: 0.1542 - val_acc: 0.9378
Epoch 56/94
 - 10s - loss: 0.1430 - acc: 0.9406 - val_loss: 0.1592 - val_acc: 0.9361
Epoch 57/94
 - 10s - loss: 0.1430 - acc: 0.9407 - val_loss: 0.1578 - val_acc: 0.9363
Epoch 58/94
 - 10s - loss: 0.1427 - acc: 0.9409 - val_loss: 0.1552 - val_acc: 0.9375
Epoch 59/94
 - 10s - loss: 0.1426 - acc: 0.9410 - val_loss: 0.1565 - val_acc: 0.9376
Epoch 60/94
 - 10s - loss: 0.1424 - acc: 0.9410 - val_loss: 0.1536 - val_acc: 0.9383
Epoch 61/94
 - 10s - loss: 0.1423 - acc: 0.9409 - val_loss: 0.1568 - val_acc: 0.9370
Epoch 62/94
 - 10s - loss: 0.1422 - acc: 0.9410 - val_loss: 0.1568 - val_acc: 0.9375
Epoch 63/94
 - 10s - loss: 0.1421 - acc: 0.9411 - val_loss: 0.1578 - val_acc: 0.9371
Epoch 64/94
 - 10s - loss: 0.1419 - acc: 0.9412 - val_loss: 0.1554 - val_acc: 0.9382
Epoch 65/94
 - 10s - loss: 0.1419 - acc: 0.9411 - val_loss: 0.1562 - val_acc: 0.9379
Epoch 66/94
 - 10s - loss: 0.1416 - acc: 0.9412 - val_loss: 0.1589 - val_acc: 0.9367
Epoch 67/94
 - 10s - loss: 0.1416 - acc: 0.9412 - val_loss: 0.1586 - val_acc: 0.9366
Epoch 68/94
 - 10s - loss: 0.1414 - acc: 0.9415 - val_loss: 0.1590 - val_acc: 0.9359
Epoch 69/94
 - 10s - loss: 0.1413 - acc: 0.9412 - val_loss: 0.1598 - val_acc: 0.9356
Epoch 70/94
 - 10s - loss: 0.1411 - acc: 0.9413 - val_loss: 0.1601 - val_acc: 0.9369
Epoch 71/94
 - 10s - loss: 0.1410 - acc: 0.9415 - val_loss: 0.1556 - val_acc: 0.9377
Epoch 72/94
 - 10s - loss: 0.1408 - acc: 0.9415 - val_loss: 0.1565 - val_acc: 0.9375
Epoch 73/94
 - 10s - loss: 0.1409 - acc: 0.9415 - val_loss: 0.1566 - val_acc: 0.9374
Epoch 74/94
 - 10s - loss: 0.1407 - acc: 0.9416 - val_loss: 0.1582 - val_acc: 0.9372
Epoch 75/94
 - 10s - loss: 0.1407 - acc: 0.9415 - val_loss: 0.1582 - val_acc: 0.9370
Epoch 76/94
 - 10s - loss: 0.1404 - acc: 0.9416 - val_loss: 0.1577 - val_acc: 0.9379
Epoch 77/94
 - 10s - loss: 0.1404 - acc: 0.9416 - val_loss: 0.1593 - val_acc: 0.9364
Epoch 78/94
 - 10s - loss: 0.1403 - acc: 0.9417 - val_loss: 0.1611 - val_acc: 0.9358
Epoch 79/94
 - 11s - loss: 0.1401 - acc: 0.9419 - val_loss: 0.1563 - val_acc: 0.9379
Epoch 80/94
 - 10s - loss: 0.1399 - acc: 0.9418 - val_loss: 0.1567 - val_acc: 0.9379
Epoch 81/94
 - 10s - loss: 0.1398 - acc: 0.9420 - val_loss: 0.1582 - val_acc: 0.9378
Epoch 82/94
 - 10s - loss: 0.1397 - acc: 0.9419 - val_loss: 0.1583 - val_acc: 0.9376
Epoch 83/94
 - 10s - loss: 0.1396 - acc: 0.9419 - val_loss: 0.1594 - val_acc: 0.9362
Epoch 84/94
 - 10s - loss: 0.1396 - acc: 0.9420 - val_loss: 0.1599 - val_acc: 0.9360
Epoch 85/94
 - 10s - loss: 0.1396 - acc: 0.9419 - val_loss: 0.1600 - val_acc: 0.9379
Epoch 86/94
 - 10s - loss: 0.1393 - acc: 0.9422 - val_loss: 0.1579 - val_acc: 0.9379
Epoch 87/94
 - 10s - loss: 0.1392 - acc: 0.9421 - val_loss: 0.1585 - val_acc: 0.9374
Epoch 88/94
 - 10s - loss: 0.1392 - acc: 0.9421 - val_loss: 0.1593 - val_acc: 0.9359
Epoch 89/94
 - 10s - loss: 0.1390 - acc: 0.9420 - val_loss: 0.1606 - val_acc: 0.9378
Epoch 90/94
 - 10s - loss: 0.1391 - acc: 0.9421 - val_loss: 0.1631 - val_acc: 0.9357
Epoch 91/94
 - 10s - loss: 0.1388 - acc: 0.9421 - val_loss: 0.1602 - val_acc: 0.9368
Epoch 92/94
 - 10s - loss: 0.1387 - acc: 0.9422 - val_loss: 0.1658 - val_acc: 0.9340
Epoch 93/94
 - 10s - loss: 0.1387 - acc: 0.9421 - val_loss: 0.1623 - val_acc: 0.9355
Epoch 94/94
 - 10s - loss: 0.1385 - acc: 0.9424 - val_loss: 0.1582 - val_acc: 0.9366
Test accuracy: 0.93656
(900000,)
(100000,)
MaxAbs

(900000, 7)
(100000, 7)
Evalutation of best performing model:

    32/100000 [..............................] - ETA: 10s
  1280/100000 [..............................] - ETA: 4s 
  2560/100000 [..............................] - ETA: 3s
  3808/100000 [>.............................] - ETA: 3s
  5056/100000 [>.............................] - ETA: 3s
  6304/100000 [>.............................] - ETA: 3s
  7552/100000 [=>............................] - ETA: 3s
  8800/100000 [=>............................] - ETA: 3s
 10048/100000 [==>...........................] - ETA: 3s
 11296/100000 [==>...........................] - ETA: 3s
 12544/100000 [==>...........................] - ETA: 3s
 13792/100000 [===>..........................] - ETA: 3s
 15040/100000 [===>..........................] - ETA: 3s
 16256/100000 [===>..........................] - ETA: 3s
 17504/100000 [====>.........................] - ETA: 3s
 18752/100000 [====>.........................] - ETA: 3s
 20000/100000 [=====>........................] - ETA: 3s
 21216/100000 [=====>........................] - ETA: 3s
 22432/100000 [=====>........................] - ETA: 3s
 23648/100000 [======>.......................] - ETA: 3s
 24864/100000 [======>.......................] - ETA: 3s
 26112/100000 [======>.......................] - ETA: 3s
 27328/100000 [=======>......................] - ETA: 2s
 28544/100000 [=======>......................] - ETA: 2s
 29760/100000 [=======>......................] - ETA: 2s
 30976/100000 [========>.....................] - ETA: 2s
 32224/100000 [========>.....................] - ETA: 2s
 33472/100000 [=========>....................] - ETA: 2s
 34720/100000 [=========>....................] - ETA: 2s
 35968/100000 [=========>....................] - ETA: 2s
 37216/100000 [==========>...................] - ETA: 2s
 38464/100000 [==========>...................] - ETA: 2s
 39712/100000 [==========>...................] - ETA: 2s
 40992/100000 [===========>..................] - ETA: 2s
 42240/100000 [===========>..................] - ETA: 2s
 43456/100000 [============>.................] - ETA: 2s
 44672/100000 [============>.................] - ETA: 2s
 45920/100000 [============>.................] - ETA: 2s
 47136/100000 [=============>................] - ETA: 2s
 48352/100000 [=============>................] - ETA: 2s
 49536/100000 [=============>................] - ETA: 2s
 50752/100000 [==============>...............] - ETA: 2s
 51968/100000 [==============>...............] - ETA: 1s
 53184/100000 [==============>...............] - ETA: 1s
 54432/100000 [===============>..............] - ETA: 1s
 55648/100000 [===============>..............] - ETA: 1s
 56896/100000 [================>.............] - ETA: 1s
 58112/100000 [================>.............] - ETA: 1s
 59360/100000 [================>.............] - ETA: 1s
 60608/100000 [=================>............] - ETA: 1s
 61856/100000 [=================>............] - ETA: 1s
 63072/100000 [=================>............] - ETA: 1s
 64288/100000 [==================>...........] - ETA: 1s
 65504/100000 [==================>...........] - ETA: 1s
 66720/100000 [===================>..........] - ETA: 1s
 67936/100000 [===================>..........] - ETA: 1s
 69152/100000 [===================>..........] - ETA: 1s
 70368/100000 [====================>.........] - ETA: 1s
 71584/100000 [====================>.........] - ETA: 1s
 72800/100000 [====================>.........] - ETA: 1s
 74016/100000 [=====================>........] - ETA: 1s
 75232/100000 [=====================>........] - ETA: 1s
 76448/100000 [=====================>........] - ETA: 0s
 77664/100000 [======================>.......] - ETA: 0s
 78880/100000 [======================>.......] - ETA: 0s
 80096/100000 [=======================>......] - ETA: 0s
 81312/100000 [=======================>......] - ETA: 0s
 82528/100000 [=======================>......] - ETA: 0s
 83744/100000 [========================>.....] - ETA: 0s
 84960/100000 [========================>.....] - ETA: 0s
 86176/100000 [========================>.....] - ETA: 0s
 87392/100000 [=========================>....] - ETA: 0s
 88608/100000 [=========================>....] - ETA: 0s
 89824/100000 [=========================>....] - ETA: 0s
 91040/100000 [==========================>...] - ETA: 0s
 92256/100000 [==========================>...] - ETA: 0s
 93472/100000 [===========================>..] - ETA: 0s
 94720/100000 [===========================>..] - ETA: 0s
 95968/100000 [===========================>..] - ETA: 0s
 97216/100000 [============================>.] - ETA: 0s
 98432/100000 [============================>.] - ETA: 0s
 99648/100000 [============================>.] - ETA: 0s
100000/100000 [==============================] - 4s 41us/step
['0.14391412032157183', '0.93928']
Best performing model chosen hyper-parameters:
{'Dense_2': 387, 'Dense_1': 649, 'Dense': 649, 'Activation': 0, 'batch_size': 238, 'epochs': 1, 'optimizer': 0}
