Using TensorFlow backend.
2018-06-28 16:07:44.689064: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-06-28 16:07:45.876753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:05:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 16:07:46.531923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:08:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 16:07:47.217110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:0d:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 16:07:47.916561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:13:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 16:07:48.629876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 4 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:83:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 16:07:49.390097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 5 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:89:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 16:07:50.126243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 6 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:8e:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 16:07:50.890529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 7 with properties: 
name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:91:00.0
totalMemory: 15.77GiB freeMemory: 15.35GiB
2018-06-28 16:07:50.914020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2018-06-28 16:07:54.130946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-28 16:07:54.131017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3 4 5 6 7 
2018-06-28 16:07:54.131029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y Y Y N N N N 
2018-06-28 16:07:54.131036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N Y Y N N N N 
2018-06-28 16:07:54.131042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   Y Y N Y N N N N 
2018-06-28 16:07:54.131049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   Y Y Y N N N N N 
2018-06-28 16:07:54.131056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 4:   N N N N N Y Y Y 
2018-06-28 16:07:54.131062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 5:   N N N N Y N Y Y 
2018-06-28 16:07:54.131069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 6:   N N N N Y Y N Y 
2018-06-28 16:07:54.131076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 7:   N N N N Y Y Y N 
2018-06-28 16:07:54.134550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14866 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 7.0)
2018-06-28 16:07:54.318228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14866 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2018-06-28 16:07:54.484275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 14866 MB memory) -> physical GPU (device: 2, name: Tesla V100-PCIE-16GB, pci bus id: 0000:0d:00.0, compute capability: 7.0)
2018-06-28 16:07:54.648961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 14866 MB memory) -> physical GPU (device: 3, name: Tesla V100-PCIE-16GB, pci bus id: 0000:13:00.0, compute capability: 7.0)
2018-06-28 16:07:54.821999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 14866 MB memory) -> physical GPU (device: 4, name: Tesla V100-PCIE-16GB, pci bus id: 0000:83:00.0, compute capability: 7.0)
2018-06-28 16:07:55.001326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 14866 MB memory) -> physical GPU (device: 5, name: Tesla V100-PCIE-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0)
2018-06-28 16:07:55.180788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 14866 MB memory) -> physical GPU (device: 6, name: Tesla V100-PCIE-16GB, pci bus id: 0000:8e:00.0, compute capability: 7.0)
2018-06-28 16:07:55.360922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 14866 MB memory) -> physical GPU (device: 7, name: Tesla V100-PCIE-16GB, pci bus id: 0000:91:00.0, compute capability: 7.0)
>>> Imports:
#coding=utf-8

from __future__ import print_function

try:
    import numpy
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation
except:
    pass

try:
    from keras.models import Sequential
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from keras.utils import to_categorical
except:
    pass

try:
    from keras.layers import LeakyReLU
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

try:
    from sklearn.model_selection import train_test_split
except:
    pass

try:
    from macros_AWS import scale_x
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'Dense': hp.choice('Dense', range(1,3001)),
        'Dropout': hp.uniform('Dropout', 0, 1),
        'Dense_1': hp.choice('Dense_1', range(1,3001)),
        'Dropout_1': hp.uniform('Dropout_1', 0, 1),
        'Dense_2': hp.choice('Dense_2', range(1,3001)),
        'Dropout_2': hp.uniform('Dropout_2', 0, 1),
        'Dense_3': hp.choice('Dense_3', range(1,3001)),
        'Dropout_3': hp.uniform('Dropout_3', 0, 1),
        'Dense_4': hp.choice('Dense_4', range(1,3001)),
        'Dropout_4': hp.uniform('Dropout_4', 0, 1),
        'Dense_5': hp.choice('Dense_5', range(1,3001)),
        'Dropout_5': hp.uniform('Dropout_5', 0, 1),
        'Dense_6': hp.choice('Dense_6', range(1,3001)),
        'Dropout_6': hp.uniform('Dropout_6', 0, 1),
        'Dense_7': hp.choice('Dense_7', range(1,3001)),
        'Dropout_7': hp.uniform('Dropout_7', 0, 1),
        'Dense_8': hp.choice('Dense_8', range(1,3001)),
        'Dropout_8': hp.uniform('Dropout_8', 0, 1),
        'Dense_9': hp.choice('Dense_9', range(1,3001)),
        'Dropout_9': hp.uniform('Dropout_9', 0, 1),
        'Activation': hp.choice('Activation', ['sigmoid']),
        'optimizer': hp.choice('optimizer', ['adam']),
        'Dense_10': hp.choice('Dense_10', range(1,3001)),
        'epochs': hp.choice('epochs', range(1,301)),
    }

>>> Data
   1: 
   2: """
   3: Data providing function:
   4: 
   5: This function is separated from create_model() so that hyperopt
   6: won't reload data for each evaluation run.
   7: """
   8: #(x_train, y_train), (x_test, y_test) = mnist.load_data()
   9: #x_train = x_train.reshape(60000, 784)
  10: #x_test = x_test.reshape(10000, 784)
  11: #x_train = x_train.astype('float32')
  12: #x_test = x_test.astype('float32')
  13: #x_train /= 255
  14: #x_test /= 255
  15: #nb_classes = 10
  16: #y_train = np_utils.to_categorical(y_train, nb_classes)
  17: #y_test = np_utils.to_categorical(y_test, nb_classes)
  18: from sklearn.model_selection import train_test_split
  19: from macros_AWS import scale_x
  20: data_directory = '/home/rice/jmc32/Gridsearch_Data/'
  21: data_sample = 'PtRegression_for_DNN_Vars_MODE_15_noBitCompr_RPC_1m_redo.npy'
  22: scaler = 'maxabs'
  23: totalset = numpy.load(data_directory + data_sample)
  24: dataset, testset = train_test_split(totalset, test_size = 0.1)
  25: # Split into input (X) and output (Y) variables
  26: x_train_prescale = dataset[:,1:]
  27: y_train = dataset[:,0]
  28: x_test_prescale = testset[:,1:]
  29: y_test = testset[:,0]
  30: # Scale
  31: print(y_train.shape)
  32: print(y_test.shape)
  33: #print(numpy.matrix(y_train))
  34: x_train, x_test = scale_x(x_train_prescale, x_test_prescale, scaler)
  35: print(x_train.shape)
  36: print(x_test.shape)
  37: #y_train= to_categorical(y_train)
  38: #y_test= to_categorical(y_test)
  39: #x_train= to_categorical(x_train)
  40: #x_test= to_categorical(x_test)
  41: 
  42: 
  43: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     """
   4:     Model providing function:
   5: 
   6:     Create Keras model with double curly brackets dropped-in as needed.
   7:     Return value has to be a valid python dictionary with two customary keys:
   8:         - loss: Specify a numeric evaluation metric to be minimized
   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible
  10:     The last one is optional, though recommended, namely:
  11:         - model: specify the model just created so that we can later use it again.
  12:     """
  13:     model = Sequential()
  14: 	#First Hidden layer and input layer
  15:     model.add(Dense(space['Dense'], input_dim=7))
  16:     model.add(LeakyReLU(alpha=0.1))
  17:     model.add(Dropout(space['Dropout']))
  18: 	#2 Hidden layer 
  19:     model.add(Dense(space['Dense_1']))
  20:     model.add(LeakyReLU(alpha=0.1))
  21:     model.add(Dropout(space['Dropout_1']))
  22: 	#3 Hidden layer 
  23:     model.add(Dense(space['Dense_2']))
  24:     model.add(LeakyReLU(alpha=0.1))
  25:     model.add(Dropout(space['Dropout_2']))
  26: 	#4 Hidden layer
  27:     model.add(Dense(space['Dense_3']))
  28:     model.add(LeakyReLU(alpha=0.1))
  29:     model.add(Dropout(space['Dropout_3']))
  30: 	#5 Hidden layer 
  31:     model.add(Dense(space['Dense_4']))
  32:     model.add(LeakyReLU(alpha=0.1))
  33:     model.add(Dropout(space['Dropout_4']))
  34: 	#6 Hidden layer 
  35:     model.add(Dense(space['Dense_5']))
  36:     model.add(LeakyReLU(alpha=0.1))
  37:     model.add(Dropout(space['Dropout_5']))
  38: 	#7 Hidden layer 
  39:     model.add(Dense(space['Dense_6']))
  40:     model.add(LeakyReLU(alpha=0.1))
  41:     model.add(Dropout(space['Dropout_6']))
  42: 	#8 Hidden layer 
  43:     model.add(Dense(space['Dense_7']))
  44:     model.add(LeakyReLU(alpha=0.1))
  45:     model.add(Dropout(space['Dropout_7']))
  46: 	#9 Hidden layer 
  47:     model.add(Dense(space['Dense_8']))
  48:     model.add(LeakyReLU(alpha=0.1))
  49:     model.add(Dropout(space['Dropout_8']))
  50: 	#10 Hidden layer 
  51:     model.add(Dense(space['Dense_9']))
  52:     model.add(LeakyReLU(alpha=0.1))
  53:     model.add(Dropout(space['Dropout_9']))
  54: 	# Output layer
  55:     model.add(Dense(1))
  56:     
  57:     model.add(Activation(space['Activation']))
  58: 
  59: 
  60:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],
  61:                   optimizer=space['optimizer'])
  62: 
  63:     model.fit(x_train, y_train,
  64:               batch_size=space['Dense_10'],
  65:               epochs=space['epochs'],
  66:               verbose=2,
  67:               validation_data=(x_test, y_test))
  68:     score, acc = model.evaluate(x_test, y_test, verbose=0)
  69:     print('Test accuracy:', acc)
  70:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}
  71: 
(900000,)
(100000,)
MaxAbs

(900000, 7)
(100000, 7)
Train on 900000 samples, validate on 100000 samples
Epoch 1/194
 - 66s - loss: 2.7933 - acc: 0.7715 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 2/194
 - 54s - loss: 6.9576 - acc: 0.5636 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 3/194
 - 54s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 4/194
 - 54s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 5/194
 - 54s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 6/194
 - 54s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 7/194
 - 54s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 8/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 9/194
 - 54s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 10/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 11/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 12/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 13/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 14/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 15/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 16/194
 - 54s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 17/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 18/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 19/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 20/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 21/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 22/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 23/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 24/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 25/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 26/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 27/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 28/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 29/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 30/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 31/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 32/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 33/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 34/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 35/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 36/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 37/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 38/194
 - 53s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 39/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 40/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 41/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 42/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 43/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 44/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 45/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 46/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 47/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 48/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 49/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 50/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 51/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 52/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 53/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 54/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 55/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 56/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 57/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 58/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 59/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 60/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 61/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 62/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 63/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 64/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 65/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 66/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 67/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 68/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 69/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 70/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 71/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 72/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 73/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 74/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 75/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 76/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 77/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 78/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 79/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 80/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 81/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 82/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 83/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 84/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 85/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 86/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 87/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 88/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 89/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 90/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 91/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 92/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 93/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 94/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 95/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 96/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 97/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 98/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 99/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 100/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 101/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 102/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 103/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 104/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 105/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 106/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 107/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 108/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 109/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 110/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 111/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 112/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 113/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 114/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 115/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 116/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 117/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 118/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 119/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 120/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 121/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 122/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 123/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 124/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 125/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 126/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 127/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 128/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 129/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 130/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 131/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 132/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 133/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 134/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 135/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 136/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 137/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 138/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 139/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 140/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 141/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 142/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 143/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 144/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 145/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 146/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 147/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 148/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 149/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 150/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 151/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 152/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 153/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 154/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 155/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 156/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 157/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 158/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 159/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 160/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 161/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 162/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 163/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 164/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 165/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 166/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 167/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 168/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 169/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 170/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 171/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 172/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 173/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 174/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 175/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 176/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 177/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 178/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 179/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 180/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 181/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 182/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 183/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 184/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 185/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 186/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 187/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 188/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 189/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 190/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 191/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 192/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 193/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 194/194
 - 52s - loss: 6.9512 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Test accuracy: 0.5667
Train on 900000 samples, validate on 100000 samples
Epoch 1/37
 - 101s - loss: 2.9805 - acc: 0.7577 - val_loss: 4.9115 - val_acc: 0.6919
Epoch 2/37
 - 99s - loss: 6.7929 - acc: 0.5741 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 3/37
 - 99s - loss: 6.8010 - acc: 0.5735 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 4/37
 - 99s - loss: 6.8198 - acc: 0.5723 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 5/37
 - 99s - loss: 6.9489 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 6/37
 - 99s - loss: 6.9482 - acc: 0.5642 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 7/37
 - 99s - loss: 6.9486 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 8/37
 - 100s - loss: 6.9489 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 9/37
 - 99s - loss: 6.9491 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 10/37
 - 99s - loss: 6.9490 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 11/37
 - 99s - loss: 6.9488 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 12/37
 - 99s - loss: 6.9489 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 13/37
 - 99s - loss: 6.9483 - acc: 0.5642 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 14/37
 - 99s - loss: 6.9490 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 15/37
 - 99s - loss: 6.9486 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 16/37
 - 99s - loss: 6.9492 - acc: 0.5641 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 17/37
 - 99s - loss: 6.8054 - acc: 0.5731 - val_loss: 5.9700 - val_acc: 0.6255
Epoch 18/37
 - 99s - loss: 6.2527 - acc: 0.6078 - val_loss: 6.7556 - val_acc: 0.5762
Epoch 19/37
 - 99s - loss: 6.8740 - acc: 0.5688 - val_loss: 6.7556 - val_acc: 0.5762
Epoch 20/37
 - 99s - loss: 6.8696 - acc: 0.5691 - val_loss: 6.7556 - val_acc: 0.5762
Epoch 21/37
 - 99s - loss: 6.8714 - acc: 0.5690 - val_loss: 6.7556 - val_acc: 0.5762
Epoch 22/37
 - 99s - loss: 6.8711 - acc: 0.5690 - val_loss: 6.7556 - val_acc: 0.5762
Epoch 23/37
 - 99s - loss: 6.8724 - acc: 0.5689 - val_loss: 6.7556 - val_acc: 0.5762
Epoch 24/37
 - 99s - loss: 6.8730 - acc: 0.5689 - val_loss: 6.7556 - val_acc: 0.5762
Epoch 25/37
 - 99s - loss: 6.8704 - acc: 0.5691 - val_loss: 6.7556 - val_acc: 0.5762
Epoch 26/37
 - 100s - loss: 6.4800 - acc: 0.5935 - val_loss: 6.0671 - val_acc: 0.6194
Epoch 27/37
 - 99s - loss: 6.3181 - acc: 0.6037 - val_loss: 6.0671 - val_acc: 0.6194
Epoch 28/37
 - 99s - loss: 6.3211 - acc: 0.6035 - val_loss: 6.0671 - val_acc: 0.6194
Epoch 29/37
 - 99s - loss: 6.3195 - acc: 0.6036 - val_loss: 6.0671 - val_acc: 0.6194
Epoch 30/37
 - 100s - loss: 6.3176 - acc: 0.6037 - val_loss: 6.0671 - val_acc: 0.6194
Epoch 31/37
 - 100s - loss: 6.3180 - acc: 0.6037 - val_loss: 6.0671 - val_acc: 0.6194
Epoch 32/37
 - 100s - loss: 6.3221 - acc: 0.6034 - val_loss: 6.0671 - val_acc: 0.6194
Epoch 33/37
 - 99s - loss: 6.3033 - acc: 0.6046 - val_loss: 5.2994 - val_acc: 0.6676
Epoch 34/37
 - 99s - loss: 6.0704 - acc: 0.6195 - val_loss: 5.2994 - val_acc: 0.6676
Epoch 35/37
 - 99s - loss: 6.0754 - acc: 0.6191 - val_loss: 5.2994 - val_acc: 0.6676
Epoch 36/37
 - 99s - loss: 6.0786 - acc: 0.6189 - val_loss: 5.2994 - val_acc: 0.6676
Epoch 37/37
 - 99s - loss: 6.6518 - acc: 0.5828 - val_loss: 6.6113 - val_acc: 0.5853
Test accuracy: 0.5853
Train on 900000 samples, validate on 100000 samples
Epoch 1/182
 - 17s - loss: 0.7385 - acc: 0.5573 - val_loss: 0.6842 - val_acc: 0.5667
Epoch 2/182
 - 15s - loss: 0.6857 - acc: 0.5636 - val_loss: 0.6855 - val_acc: 0.5667
Epoch 3/182
 - 15s - loss: 0.6670 - acc: 0.5962 - val_loss: 0.9080 - val_acc: 0.5667
Epoch 4/182
 - 15s - loss: 0.5956 - acc: 0.6690 - val_loss: 1.6556 - val_acc: 0.5668
Epoch 5/182
 - 15s - loss: 0.5454 - acc: 0.7040 - val_loss: 1.5245 - val_acc: 0.5668
Epoch 6/182
 - 15s - loss: 0.5234 - acc: 0.7194 - val_loss: 1.5429 - val_acc: 0.5667
Epoch 7/182
 - 15s - loss: 0.5104 - acc: 0.7256 - val_loss: 0.6503 - val_acc: 0.5682
Epoch 8/182
 - 15s - loss: 0.4969 - acc: 0.7341 - val_loss: 0.5991 - val_acc: 0.6162
Epoch 9/182
 - 15s - loss: 0.4917 - acc: 0.7371 - val_loss: 0.7156 - val_acc: 0.6043
Epoch 10/182
 - 15s - loss: 0.4916 - acc: 0.7374 - val_loss: 0.7533 - val_acc: 0.5954
Epoch 11/182
 - 15s - loss: 0.4892 - acc: 0.7389 - val_loss: 0.6655 - val_acc: 0.5710
Epoch 12/182
 - 15s - loss: 0.4952 - acc: 0.7367 - val_loss: 0.8333 - val_acc: 0.5711
Epoch 13/182
 - 15s - loss: 0.4953 - acc: 0.7355 - val_loss: 0.9779 - val_acc: 0.5728
Epoch 14/182
 - 15s - loss: 0.4997 - acc: 0.7350 - val_loss: 1.1599 - val_acc: 0.5675
Epoch 15/182
 - 15s - loss: 0.4984 - acc: 0.7351 - val_loss: 1.0906 - val_acc: 0.5719
Epoch 16/182
 - 15s - loss: 0.4990 - acc: 0.7343 - val_loss: 1.0380 - val_acc: 0.5668
Epoch 17/182
 - 15s - loss: 0.4981 - acc: 0.7346 - val_loss: 1.1588 - val_acc: 0.5785
Epoch 18/182
 - 15s - loss: 0.4974 - acc: 0.7353 - val_loss: 0.9096 - val_acc: 0.5818
Epoch 19/182
 - 15s - loss: 0.5088 - acc: 0.7327 - val_loss: 0.8740 - val_acc: 0.5709
Epoch 20/182
 - 15s - loss: 0.4973 - acc: 0.7354 - val_loss: 0.8590 - val_acc: 0.6233
Epoch 21/182
 - 15s - loss: 0.4961 - acc: 0.7359 - val_loss: 1.1200 - val_acc: 0.6051
Epoch 22/182
 - 15s - loss: 0.5030 - acc: 0.7352 - val_loss: 1.2624 - val_acc: 0.6448
Epoch 23/182
 - 15s - loss: 0.5005 - acc: 0.7357 - val_loss: 1.1182 - val_acc: 0.6262
Epoch 24/182
 - 15s - loss: 0.4950 - acc: 0.7372 - val_loss: 0.9230 - val_acc: 0.6792
Epoch 25/182
 - 15s - loss: 0.4952 - acc: 0.7367 - val_loss: 1.1805 - val_acc: 0.6305
Epoch 26/182
 - 15s - loss: 0.5159 - acc: 0.7317 - val_loss: 1.2947 - val_acc: 0.6552
Epoch 27/182
 - 15s - loss: 0.5022 - acc: 0.7347 - val_loss: 0.9978 - val_acc: 0.6887
Epoch 28/182
 - 15s - loss: 0.4977 - acc: 0.7360 - val_loss: 0.9283 - val_acc: 0.6474
Epoch 29/182
 - 15s - loss: 0.4972 - acc: 0.7364 - val_loss: 0.8020 - val_acc: 0.6488
Epoch 30/182
 - 15s - loss: 0.5049 - acc: 0.7342 - val_loss: 1.0404 - val_acc: 0.6596
Epoch 31/182
 - 15s - loss: 0.5056 - acc: 0.7341 - val_loss: 0.8818 - val_acc: 0.6311
Epoch 32/182
 - 15s - loss: 0.4995 - acc: 0.7348 - val_loss: 0.7737 - val_acc: 0.6888
Epoch 33/182
 - 15s - loss: 0.5180 - acc: 0.7304 - val_loss: 1.2304 - val_acc: 0.6613
Epoch 34/182
 - 15s - loss: 0.5109 - acc: 0.7323 - val_loss: 0.9993 - val_acc: 0.6463
Epoch 35/182
 - 15s - loss: 0.5074 - acc: 0.7335 - val_loss: 1.0161 - val_acc: 0.6234
Epoch 36/182
 - 15s - loss: 0.5087 - acc: 0.7322 - val_loss: 0.8822 - val_acc: 0.6515
Epoch 37/182
 - 15s - loss: 0.5226 - acc: 0.7287 - val_loss: 1.1261 - val_acc: 0.6340
Epoch 38/182
 - 15s - loss: 0.5631 - acc: 0.7213 - val_loss: 0.8777 - val_acc: 0.6391
Epoch 39/182
 - 15s - loss: 0.5302 - acc: 0.7275 - val_loss: 1.0213 - val_acc: 0.6337
Epoch 40/182
 - 15s - loss: 0.5109 - acc: 0.7322 - val_loss: 0.9570 - val_acc: 0.6125
Epoch 41/182
 - 15s - loss: 0.5118 - acc: 0.7317 - val_loss: 0.8850 - val_acc: 0.6373
Epoch 42/182
 - 15s - loss: 0.5094 - acc: 0.7327 - val_loss: 0.9356 - val_acc: 0.6316
Epoch 43/182
 - 15s - loss: 3.1803 - acc: 0.5509 - val_loss: 3.4194 - val_acc: 0.7484
Epoch 44/182
 - 15s - loss: 6.4431 - acc: 0.5036 - val_loss: 12.7831 - val_acc: 0.2038
Epoch 45/182
 - 15s - loss: 8.3539 - acc: 0.4753 - val_loss: 13.5046 - val_acc: 0.1588
Epoch 46/182
 - 15s - loss: 9.0446 - acc: 0.4385 - val_loss: 13.2312 - val_acc: 0.1761
Epoch 47/182
 - 15s - loss: 8.9543 - acc: 0.4440 - val_loss: 12.4395 - val_acc: 0.2259
Epoch 48/182
 - 15s - loss: 8.9046 - acc: 0.4470 - val_loss: 9.1566 - val_acc: 0.4318
Epoch 49/182
 - 15s - loss: 9.0300 - acc: 0.4396 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 50/182
 - 15s - loss: 9.0549 - acc: 0.4381 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 51/182
 - 15s - loss: 9.0698 - acc: 0.4372 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 52/182
 - 15s - loss: 9.0878 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 53/182
 - 15s - loss: 9.0884 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 54/182
 - 15s - loss: 9.0872 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 55/182
 - 15s - loss: 9.0877 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 56/182
 - 15s - loss: 9.0879 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 57/182
 - 15s - loss: 9.0870 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 58/182
 - 15s - loss: 9.0865 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 59/182
 - 15s - loss: 9.0873 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 60/182
 - 15s - loss: 9.0870 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 61/182
 - 15s - loss: 9.0882 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 62/182
 - 15s - loss: 9.0887 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 63/182
 - 15s - loss: 9.0873 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 64/182
 - 15s - loss: 9.0875 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 65/182
 - 15s - loss: 9.0869 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 66/182
 - 15s - loss: 9.0857 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 67/182
 - 15s - loss: 9.0860 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 68/182
 - 15s - loss: 9.0841 - acc: 0.4364 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 69/182
 - 15s - loss: 9.0862 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 70/182
 - 15s - loss: 9.0860 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 71/182
 - 15s - loss: 9.0860 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 72/182
 - 15s - loss: 9.0864 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 73/182
 - 15s - loss: 9.0886 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 74/182
 - 15s - loss: 9.0869 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 75/182
 - 15s - loss: 9.0861 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 76/182
 - 15s - loss: 9.0872 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 77/182
 - 15s - loss: 9.0848 - acc: 0.4364 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 78/182
 - 15s - loss: 9.0852 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 79/182
 - 15s - loss: 9.0869 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 80/182
 - 15s - loss: 9.0853 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 81/182
 - 15s - loss: 9.0858 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 82/182
 - 15s - loss: 9.0864 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 83/182
 - 15s - loss: 9.0869 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 84/182
 - 15s - loss: 9.0880 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 85/182
 - 15s - loss: 9.0866 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 86/182
 - 15s - loss: 9.0852 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 87/182
 - 15s - loss: 9.0866 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 88/182
 - 15s - loss: 9.0866 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 89/182
 - 15s - loss: 9.0858 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 90/182
 - 15s - loss: 9.0856 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 91/182
 - 15s - loss: 9.0862 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 92/182
 - 15s - loss: 9.0848 - acc: 0.4364 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 93/182
 - 15s - loss: 9.0872 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 94/182
 - 15s - loss: 9.0857 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 95/182
 - 15s - loss: 9.0858 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 96/182
 - 15s - loss: 9.0848 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 97/182
 - 15s - loss: 9.0869 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 98/182
 - 15s - loss: 9.0860 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 99/182
 - 15s - loss: 9.0850 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 100/182
 - 15s - loss: 9.0858 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 101/182
 - 15s - loss: 9.0848 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 102/182
 - 15s - loss: 9.0854 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 103/182
 - 15s - loss: 9.0862 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 104/182
 - 15s - loss: 9.0869 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 105/182
 - 15s - loss: 9.0847 - acc: 0.4364 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 106/182
 - 15s - loss: 9.0862 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 107/182
 - 15s - loss: 9.0858 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 108/182
 - 15s - loss: 9.0869 - acc: 0.4362 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 109/182
 - 15s - loss: 9.0851 - acc: 0.4363 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 110/182
 - 15s - loss: 9.0741 - acc: 0.4370 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 111/182
 - 15s - loss: 9.0721 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 112/182
 - 15s - loss: 9.0740 - acc: 0.4370 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 113/182
 - 15s - loss: 9.0716 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 114/182
 - 15s - loss: 9.0745 - acc: 0.4370 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 115/182
 - 15s - loss: 9.0739 - acc: 0.4370 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 116/182
 - 15s - loss: 9.0720 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 117/182
 - 15s - loss: 9.0731 - acc: 0.4370 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 118/182
 - 15s - loss: 9.0737 - acc: 0.4370 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 119/182
 - 15s - loss: 9.0721 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 120/182
 - 15s - loss: 9.0723 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 121/182
 - 15s - loss: 9.0723 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 122/182
 - 15s - loss: 9.0728 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 123/182
 - 15s - loss: 9.0704 - acc: 0.4372 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 124/182
 - 15s - loss: 9.0725 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 125/182
 - 15s - loss: 9.0700 - acc: 0.4372 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 126/182
 - 15s - loss: 9.0714 - acc: 0.4372 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 127/182
 - 15s - loss: 9.0696 - acc: 0.4373 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 128/182
 - 15s - loss: 9.0733 - acc: 0.4370 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 129/182
 - 15s - loss: 9.0730 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 130/182
 - 15s - loss: 9.0704 - acc: 0.4372 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 131/182
 - 15s - loss: 9.0692 - acc: 0.4373 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 132/182
 - 15s - loss: 9.0750 - acc: 0.4369 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 133/182
 - 15s - loss: 9.0719 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 134/182
 - 15s - loss: 9.0721 - acc: 0.4371 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 135/182
 - 15s - loss: 9.0893 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 136/182
 - 15s - loss: 9.0897 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 137/182
 - 15s - loss: 9.0898 - acc: 0.4360 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 138/182
 - 15s - loss: 9.0889 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 139/182
 - 15s - loss: 9.0896 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 140/182
 - 15s - loss: 9.0892 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 141/182
 - 15s - loss: 9.0887 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 142/182
 - 15s - loss: 9.0892 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 143/182
 - 15s - loss: 9.0894 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 144/182
 - 15s - loss: 9.0895 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 145/182
 - 15s - loss: 9.0898 - acc: 0.4360 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 146/182
 - 15s - loss: 9.0892 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 147/182
 - 15s - loss: 9.0895 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 148/182
 - 15s - loss: 9.0894 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 149/182
 - 15s - loss: 9.0889 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 150/182
 - 15s - loss: 9.0894 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 151/182
 - 15s - loss: 9.0893 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 152/182
 - 15s - loss: 9.0893 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 153/182
 - 15s - loss: 9.0892 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 154/182
 - 15s - loss: 9.0892 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 155/182
 - 15s - loss: 9.0893 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 156/182
 - 15s - loss: 9.0892 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 157/182
 - 15s - loss: 9.0889 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 158/182
 - 15s - loss: 9.0896 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 159/182
 - 15s - loss: 9.0894 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 160/182
 - 15s - loss: 9.0897 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 161/182
 - 15s - loss: 9.0896 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 162/182
 - 15s - loss: 9.0889 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 163/182
 - 15s - loss: 9.0893 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 164/182
 - 15s - loss: 9.0891 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 165/182
 - 15s - loss: 9.0891 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 166/182
 - 15s - loss: 9.0896 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 167/182
 - 15s - loss: 9.0893 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 168/182
 - 15s - loss: 9.0889 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 169/182
 - 15s - loss: 9.0892 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 170/182
 - 15s - loss: 9.0900 - acc: 0.4360 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 171/182
 - 15s - loss: 9.0897 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 172/182
 - 15s - loss: 9.0896 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 173/182
 - 15s - loss: 9.0893 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 174/182
 - 15s - loss: 9.0893 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 175/182
 - 15s - loss: 9.0895 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 176/182
 - 15s - loss: 9.0895 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 177/182
 - 15s - loss: 9.0899 - acc: 0.4360 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 178/182
 - 15s - loss: 9.0894 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 179/182
 - 15s - loss: 9.0892 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 180/182
 - 15s - loss: 9.0891 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 181/182
 - 15s - loss: 9.0898 - acc: 0.4360 - val_loss: 9.1341 - val_acc: 0.4333
Epoch 182/182
 - 15s - loss: 9.0895 - acc: 0.4361 - val_loss: 9.1341 - val_acc: 0.4333
Test accuracy: 0.4333
Train on 900000 samples, validate on 100000 samples
Epoch 1/112
 - 14s - loss: 0.3047 - acc: 0.8705 - val_loss: 0.2170 - val_acc: 0.9155
Epoch 2/112
 - 13s - loss: 0.2366 - acc: 0.9071 - val_loss: 0.2124 - val_acc: 0.9098
Epoch 3/112
 - 13s - loss: 0.2287 - acc: 0.9096 - val_loss: 0.1984 - val_acc: 0.9207
Epoch 4/112
 - 13s - loss: 0.2232 - acc: 0.9114 - val_loss: 0.1965 - val_acc: 0.9186
Epoch 5/112
 - 13s - loss: 0.2208 - acc: 0.9127 - val_loss: 0.1912 - val_acc: 0.9234
Epoch 6/112
 - 13s - loss: 0.2252 - acc: 0.9113 - val_loss: 0.2092 - val_acc: 0.9182
Epoch 7/112
 - 13s - loss: 0.2201 - acc: 0.9134 - val_loss: 0.2043 - val_acc: 0.9179
Epoch 8/112
 - 13s - loss: 0.2195 - acc: 0.9135 - val_loss: 0.1908 - val_acc: 0.9210
Epoch 9/112
 - 13s - loss: 0.2185 - acc: 0.9141 - val_loss: 0.1973 - val_acc: 0.9200
Epoch 10/112
 - 13s - loss: 0.2172 - acc: 0.9150 - val_loss: 0.1885 - val_acc: 0.9252
Epoch 11/112
 - 13s - loss: 0.2225 - acc: 0.9136 - val_loss: 0.1902 - val_acc: 0.9236
Epoch 12/112
 - 13s - loss: 0.2170 - acc: 0.9154 - val_loss: 0.1954 - val_acc: 0.9206
Epoch 13/112
 - 13s - loss: 0.2266 - acc: 0.9124 - val_loss: 0.1957 - val_acc: 0.9203
Epoch 14/112
 - 13s - loss: 0.2210 - acc: 0.9142 - val_loss: 0.2029 - val_acc: 0.9155
Epoch 15/112
 - 13s - loss: 0.2189 - acc: 0.9153 - val_loss: 0.1894 - val_acc: 0.9263
Epoch 16/112
 - 13s - loss: 0.2200 - acc: 0.9152 - val_loss: 0.1899 - val_acc: 0.9245
Epoch 17/112
 - 13s - loss: 0.2178 - acc: 0.9158 - val_loss: 0.1900 - val_acc: 0.9255
Epoch 18/112
 - 13s - loss: 0.2153 - acc: 0.9164 - val_loss: 0.1908 - val_acc: 0.9264
Epoch 19/112
 - 13s - loss: 0.2132 - acc: 0.9176 - val_loss: 0.1893 - val_acc: 0.9263
Epoch 20/112
 - 13s - loss: 0.2155 - acc: 0.9171 - val_loss: 0.1826 - val_acc: 0.9278
Epoch 21/112
 - 13s - loss: 0.2147 - acc: 0.9171 - val_loss: 0.1941 - val_acc: 0.9267
Epoch 22/112
 - 13s - loss: 0.2159 - acc: 0.9171 - val_loss: 0.1853 - val_acc: 0.9275
Epoch 23/112
 - 13s - loss: 0.2315 - acc: 0.9132 - val_loss: 0.1946 - val_acc: 0.9269
Epoch 24/112
 - 13s - loss: 0.2153 - acc: 0.9174 - val_loss: 0.1937 - val_acc: 0.9265
Epoch 25/112
 - 13s - loss: 0.2150 - acc: 0.9177 - val_loss: 0.1966 - val_acc: 0.9271
Epoch 26/112
 - 13s - loss: 0.2157 - acc: 0.9176 - val_loss: 0.1899 - val_acc: 0.9273
Epoch 27/112
 - 13s - loss: 0.2141 - acc: 0.9184 - val_loss: 0.1984 - val_acc: 0.9222
Epoch 28/112
 - 13s - loss: 0.2131 - acc: 0.9188 - val_loss: 0.1915 - val_acc: 0.9284
Epoch 29/112
 - 13s - loss: 0.2101 - acc: 0.9198 - val_loss: 0.1876 - val_acc: 0.9298
Epoch 30/112
 - 13s - loss: 0.2165 - acc: 0.9180 - val_loss: 0.2019 - val_acc: 0.9203
Epoch 31/112
 - 13s - loss: 0.2253 - acc: 0.9157 - val_loss: 0.1954 - val_acc: 0.9259
Epoch 32/112
 - 13s - loss: 0.2192 - acc: 0.9172 - val_loss: 0.1906 - val_acc: 0.9257
Epoch 33/112
 - 13s - loss: 0.2164 - acc: 0.9182 - val_loss: 0.1841 - val_acc: 0.9273
Epoch 34/112
 - 13s - loss: 0.2183 - acc: 0.9175 - val_loss: 0.1826 - val_acc: 0.9292
Epoch 35/112
 - 13s - loss: 0.2153 - acc: 0.9185 - val_loss: 0.2054 - val_acc: 0.9277
Epoch 36/112
 - 13s - loss: 0.2164 - acc: 0.9177 - val_loss: 0.1879 - val_acc: 0.9281
Epoch 37/112
 - 13s - loss: 0.2152 - acc: 0.9190 - val_loss: 0.1968 - val_acc: 0.9278
Epoch 38/112
 - 13s - loss: 0.2202 - acc: 0.9178 - val_loss: 0.1933 - val_acc: 0.9231
Epoch 39/112
 - 13s - loss: 0.2187 - acc: 0.9181 - val_loss: 0.1918 - val_acc: 0.9297
Epoch 40/112
 - 13s - loss: 0.2286 - acc: 0.9150 - val_loss: 0.2218 - val_acc: 0.9137
Epoch 41/112
 - 13s - loss: 0.2282 - acc: 0.9147 - val_loss: 0.1817 - val_acc: 0.9289
Epoch 42/112
 - 13s - loss: 0.2169 - acc: 0.9185 - val_loss: 0.1923 - val_acc: 0.9293
Epoch 43/112
 - 13s - loss: 0.2411 - acc: 0.9128 - val_loss: 0.1865 - val_acc: 0.9271
Epoch 44/112
 - 13s - loss: 0.2168 - acc: 0.9186 - val_loss: 0.1946 - val_acc: 0.9275
Epoch 45/112
 - 13s - loss: 0.2106 - acc: 0.9203 - val_loss: 0.1908 - val_acc: 0.9284
Epoch 46/112
 - 13s - loss: 0.2100 - acc: 0.9206 - val_loss: 0.1793 - val_acc: 0.9300
Epoch 47/112
 - 13s - loss: 0.2372 - acc: 0.9133 - val_loss: 0.1895 - val_acc: 0.9301
Epoch 48/112
 - 13s - loss: 0.2326 - acc: 0.9143 - val_loss: 0.2006 - val_acc: 0.9255
Epoch 49/112
 - 13s - loss: 0.3046 - acc: 0.8888 - val_loss: 0.2097 - val_acc: 0.9226
Epoch 50/112
 - 13s - loss: 0.2379 - acc: 0.9112 - val_loss: 0.2070 - val_acc: 0.9252
Epoch 51/112
 - 13s - loss: 0.2250 - acc: 0.9157 - val_loss: 0.1949 - val_acc: 0.9275
Epoch 52/112
 - 13s - loss: 0.2244 - acc: 0.9159 - val_loss: 0.2070 - val_acc: 0.9270
Epoch 53/112
 - 13s - loss: 0.2204 - acc: 0.9176 - val_loss: 0.1884 - val_acc: 0.9290
Epoch 54/112
 - 13s - loss: 0.2247 - acc: 0.9160 - val_loss: 0.2019 - val_acc: 0.9262
Epoch 55/112
 - 13s - loss: 0.2229 - acc: 0.9168 - val_loss: 0.2125 - val_acc: 0.9247
Epoch 56/112
 - 13s - loss: 0.2220 - acc: 0.9174 - val_loss: 0.1918 - val_acc: 0.9244
Epoch 57/112
 - 13s - loss: 0.2288 - acc: 0.9158 - val_loss: 0.2135 - val_acc: 0.9080
Epoch 58/112
 - 13s - loss: 0.2745 - acc: 0.9004 - val_loss: 0.2044 - val_acc: 0.9238
Epoch 59/112
 - 13s - loss: 0.2244 - acc: 0.9164 - val_loss: 0.1991 - val_acc: 0.9239
Epoch 60/112
 - 13s - loss: 5.2435 - acc: 0.6489 - val_loss: 3.2136 - val_acc: 0.7984
Epoch 61/112
 - 13s - loss: 7.2205 - acc: 0.5495 - val_loss: 6.7234 - val_acc: 0.5784
Epoch 62/112
 - 13s - loss: 6.8602 - acc: 0.5717 - val_loss: 3.2032 - val_acc: 0.7992
Epoch 63/112
 - 13s - loss: 6.6639 - acc: 0.5840 - val_loss: 5.2121 - val_acc: 0.6755
Epoch 64/112
 - 13s - loss: 7.0126 - acc: 0.5625 - val_loss: 9.6158 - val_acc: 0.4027
Epoch 65/112
 - 13s - loss: 8.7492 - acc: 0.4565 - val_loss: 9.1132 - val_acc: 0.4340
Epoch 66/112
 - 13s - loss: 8.4361 - acc: 0.4760 - val_loss: 9.1734 - val_acc: 0.4303
Epoch 67/112
 - 13s - loss: 7.7995 - acc: 0.5153 - val_loss: 5.0224 - val_acc: 0.6878
Epoch 68/112
 - 13s - loss: 7.6537 - acc: 0.5243 - val_loss: 5.0224 - val_acc: 0.6878
Epoch 69/112
 - 13s - loss: 7.6635 - acc: 0.5237 - val_loss: 5.0224 - val_acc: 0.6878
Epoch 70/112
 - 13s - loss: 7.7167 - acc: 0.5204 - val_loss: 9.2902 - val_acc: 0.4231
Epoch 71/112
 - 13s - loss: 8.1792 - acc: 0.4916 - val_loss: 9.2912 - val_acc: 0.4230
Epoch 72/112
 - 13s - loss: 8.1615 - acc: 0.4927 - val_loss: 9.2912 - val_acc: 0.4230
Epoch 73/112
 - 13s - loss: 8.1600 - acc: 0.4928 - val_loss: 9.2912 - val_acc: 0.4230
Epoch 74/112
 - 13s - loss: 9.0732 - acc: 0.4364 - val_loss: 9.1579 - val_acc: 0.4318
Epoch 75/112
 - 13s - loss: 9.2332 - acc: 0.4265 - val_loss: 9.1579 - val_acc: 0.4318
Epoch 76/112
 - 13s - loss: 9.2228 - acc: 0.4272 - val_loss: 9.1579 - val_acc: 0.4318
Epoch 77/112
 - 13s - loss: 9.2230 - acc: 0.4272 - val_loss: 9.1694 - val_acc: 0.4311
Epoch 78/112
 - 13s - loss: 8.2044 - acc: 0.4902 - val_loss: 9.2477 - val_acc: 0.4261
Epoch 79/112
 - 13s - loss: 8.2072 - acc: 0.4900 - val_loss: 9.2477 - val_acc: 0.4261
Epoch 80/112
 - 13s - loss: 8.1968 - acc: 0.4907 - val_loss: 9.2477 - val_acc: 0.4261
Epoch 81/112
 - 13s - loss: 8.2031 - acc: 0.4903 - val_loss: 9.2477 - val_acc: 0.4261
Epoch 82/112
 - 13s - loss: 8.1993 - acc: 0.4905 - val_loss: 9.2477 - val_acc: 0.4261
Epoch 83/112
 - 13s - loss: 8.1990 - acc: 0.4906 - val_loss: 9.2477 - val_acc: 0.4261
Epoch 84/112
 - 13s - loss: 8.2232 - acc: 0.4890 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 85/112
 - 13s - loss: 8.3164 - acc: 0.4830 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 86/112
 - 13s - loss: 8.3218 - acc: 0.4826 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 87/112
 - 13s - loss: 8.3284 - acc: 0.4822 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 88/112
 - 13s - loss: 8.3200 - acc: 0.4827 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 89/112
 - 13s - loss: 8.3331 - acc: 0.4819 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 90/112
 - 13s - loss: 8.3050 - acc: 0.4837 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 91/112
 - 13s - loss: 8.3362 - acc: 0.4817 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 92/112
 - 13s - loss: 8.3196 - acc: 0.4828 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 93/112
 - 13s - loss: 8.3180 - acc: 0.4829 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 94/112
 - 13s - loss: 8.3132 - acc: 0.4832 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 95/112
 - 13s - loss: 8.3228 - acc: 0.4826 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 96/112
 - 13s - loss: 8.3138 - acc: 0.4831 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 97/112
 - 13s - loss: 8.3199 - acc: 0.4827 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 98/112
 - 13s - loss: 8.3067 - acc: 0.4836 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 99/112
 - 13s - loss: 8.3233 - acc: 0.4825 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 100/112
 - 13s - loss: 8.3186 - acc: 0.4828 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 101/112
 - 13s - loss: 8.3128 - acc: 0.4832 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 102/112
 - 13s - loss: 8.3092 - acc: 0.4834 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 103/112
 - 13s - loss: 8.3119 - acc: 0.4832 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 104/112
 - 13s - loss: 8.3246 - acc: 0.4824 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 105/112
 - 13s - loss: 8.3110 - acc: 0.4833 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 106/112
 - 13s - loss: 8.3269 - acc: 0.4823 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 107/112
 - 13s - loss: 8.3384 - acc: 0.4816 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 108/112
 - 13s - loss: 8.3240 - acc: 0.4825 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 109/112
 - 13s - loss: 8.3293 - acc: 0.4822 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 110/112
 - 13s - loss: 8.3258 - acc: 0.4824 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 111/112
 - 13s - loss: 8.3259 - acc: 0.4824 - val_loss: 8.1164 - val_acc: 0.4961
Epoch 112/112
 - 13s - loss: 8.3227 - acc: 0.4826 - val_loss: 8.1164 - val_acc: 0.4961
Test accuracy: 0.49608
Train on 900000 samples, validate on 100000 samples
Epoch 1/92
 - 19s - loss: 0.2900 - acc: 0.8775 - val_loss: 0.2488 - val_acc: 0.9075
Epoch 2/92
 - 18s - loss: 0.2124 - acc: 0.9182 - val_loss: 0.2112 - val_acc: 0.9257
Epoch 3/92
 - 18s - loss: 0.2030 - acc: 0.9226 - val_loss: 0.1994 - val_acc: 0.9299
Epoch 4/92
 - 18s - loss: 0.1990 - acc: 0.9248 - val_loss: 0.1916 - val_acc: 0.9304
Epoch 5/92
 - 18s - loss: 0.1994 - acc: 0.9249 - val_loss: 0.1983 - val_acc: 0.9278
Epoch 6/92
 - 18s - loss: 0.2038 - acc: 0.9244 - val_loss: 0.1859 - val_acc: 0.9338
Epoch 7/92
 - 18s - loss: 0.2101 - acc: 0.9228 - val_loss: 0.1829 - val_acc: 0.9330
Epoch 8/92
 - 17s - loss: 0.2069 - acc: 0.9235 - val_loss: 0.1815 - val_acc: 0.9350
Epoch 9/92
 - 18s - loss: 0.2077 - acc: 0.9236 - val_loss: 0.2170 - val_acc: 0.9316
Epoch 10/92
 - 18s - loss: 0.2233 - acc: 0.9183 - val_loss: 0.2026 - val_acc: 0.9331
Epoch 11/92
 - 17s - loss: 0.2175 - acc: 0.9203 - val_loss: 0.2308 - val_acc: 0.9285
Epoch 12/92
 - 18s - loss: 0.2437 - acc: 0.9114 - val_loss: 0.2122 - val_acc: 0.9279
Epoch 13/92
 - 17s - loss: 0.2160 - acc: 0.9202 - val_loss: 0.2055 - val_acc: 0.9280
Epoch 14/92
 - 18s - loss: 0.2304 - acc: 0.9166 - val_loss: 0.2125 - val_acc: 0.9309
Epoch 15/92
 - 17s - loss: 0.2451 - acc: 0.9115 - val_loss: 0.2303 - val_acc: 0.9273
Epoch 16/92
 - 18s - loss: 0.2683 - acc: 0.9042 - val_loss: 0.2222 - val_acc: 0.9163
Epoch 17/92
 - 18s - loss: 0.2606 - acc: 0.9087 - val_loss: 0.2037 - val_acc: 0.9266
Epoch 18/92
 - 17s - loss: 0.2437 - acc: 0.9126 - val_loss: 0.2104 - val_acc: 0.9257
Epoch 19/92
 - 17s - loss: 0.2265 - acc: 0.9168 - val_loss: 0.2086 - val_acc: 0.9299
Epoch 20/92
 - 17s - loss: 0.2607 - acc: 0.9070 - val_loss: 0.1977 - val_acc: 0.9314
Epoch 21/92
 - 17s - loss: 0.2839 - acc: 0.8997 - val_loss: 0.2226 - val_acc: 0.9168
Epoch 22/92
 - 17s - loss: 0.2567 - acc: 0.9067 - val_loss: 0.2109 - val_acc: 0.9274
Epoch 23/92
 - 17s - loss: 0.2312 - acc: 0.9150 - val_loss: 0.2158 - val_acc: 0.9282
Epoch 24/92
 - 17s - loss: 0.2818 - acc: 0.9018 - val_loss: 0.2363 - val_acc: 0.9237
Epoch 25/92
 - 17s - loss: 0.2880 - acc: 0.8998 - val_loss: 0.2202 - val_acc: 0.9206
Epoch 26/92
 - 17s - loss: 0.3023 - acc: 0.8955 - val_loss: 0.2592 - val_acc: 0.8854
Epoch 27/92
 - 17s - loss: 0.3059 - acc: 0.8928 - val_loss: 0.2438 - val_acc: 0.9026
Epoch 28/92
 - 17s - loss: 0.3043 - acc: 0.8916 - val_loss: 0.2322 - val_acc: 0.8997
Epoch 29/92
 - 17s - loss: 0.2634 - acc: 0.9038 - val_loss: 0.2166 - val_acc: 0.9221
Epoch 30/92
 - 17s - loss: 0.2735 - acc: 0.9015 - val_loss: 0.2583 - val_acc: 0.8880
Epoch 31/92
 - 17s - loss: 0.2457 - acc: 0.9098 - val_loss: 0.2152 - val_acc: 0.9185
Epoch 32/92
 - 17s - loss: 0.2380 - acc: 0.9127 - val_loss: 0.2363 - val_acc: 0.8958
Epoch 33/92
 - 17s - loss: 0.3344 - acc: 0.8865 - val_loss: 0.2309 - val_acc: 0.8989
Epoch 34/92
 - 17s - loss: 0.2688 - acc: 0.9033 - val_loss: 0.2477 - val_acc: 0.8872
Epoch 35/92
 - 17s - loss: 0.3182 - acc: 0.8893 - val_loss: 0.2688 - val_acc: 0.8725
Epoch 36/92
 - 17s - loss: 0.3326 - acc: 0.8901 - val_loss: 0.2974 - val_acc: 0.8549
Epoch 37/92
 - 17s - loss: 0.4975 - acc: 0.8588 - val_loss: 0.3687 - val_acc: 0.8263
Epoch 38/92
 - 17s - loss: 1.7743 - acc: 0.7974 - val_loss: 4.2880 - val_acc: 0.7310
Epoch 39/92
 - 18s - loss: 6.6310 - acc: 0.5842 - val_loss: 6.9066 - val_acc: 0.5668
Epoch 40/92
 - 18s - loss: 6.8618 - acc: 0.5696 - val_loss: 6.9066 - val_acc: 0.5668
Epoch 41/92
 - 18s - loss: 6.8626 - acc: 0.5696 - val_loss: 6.9066 - val_acc: 0.5668
Epoch 42/92
 - 18s - loss: 6.8647 - acc: 0.5694 - val_loss: 6.9066 - val_acc: 0.5668
Epoch 43/92
 - 18s - loss: 6.8638 - acc: 0.5695 - val_loss: 6.9066 - val_acc: 0.5668
Epoch 44/92
 - 18s - loss: 6.9183 - acc: 0.5661 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 45/92
 - 18s - loss: 6.9382 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 46/92
 - 18s - loss: 6.9369 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 47/92
 - 18s - loss: 6.9373 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 48/92
 - 18s - loss: 6.9381 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 49/92
 - 18s - loss: 6.9372 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 50/92
 - 18s - loss: 6.9362 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 51/92
 - 18s - loss: 6.9380 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 52/92
 - 18s - loss: 6.9376 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 53/92
 - 18s - loss: 6.9380 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 54/92
 - 18s - loss: 6.9370 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 55/92
 - 18s - loss: 6.9382 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 56/92
 - 18s - loss: 6.9376 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 57/92
 - 18s - loss: 6.9383 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 58/92
 - 18s - loss: 6.9374 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 59/92
 - 18s - loss: 6.9369 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 60/92
 - 18s - loss: 6.9360 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 61/92
 - 18s - loss: 6.9371 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 62/92
 - 18s - loss: 6.9370 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 63/92
 - 18s - loss: 6.9386 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 64/92
 - 18s - loss: 6.9378 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 65/92
 - 18s - loss: 6.9369 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 66/92
 - 18s - loss: 6.9383 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 67/92
 - 18s - loss: 6.9372 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 68/92
 - 18s - loss: 6.9367 - acc: 0.5649 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 69/92
 - 18s - loss: 6.9381 - acc: 0.5648 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 70/92
 - 18s - loss: 6.9314 - acc: 0.5652 - val_loss: 6.8970 - val_acc: 0.5674
Epoch 71/92
 - 18s - loss: 6.9237 - acc: 0.5657 - val_loss: 6.8970 - val_acc: 0.5674
Epoch 72/92
 - 18s - loss: 6.9253 - acc: 0.5656 - val_loss: 6.8970 - val_acc: 0.5674
Epoch 73/92
 - 18s - loss: 6.9244 - acc: 0.5657 - val_loss: 6.8970 - val_acc: 0.5674
Epoch 74/92
 - 18s - loss: 6.9304 - acc: 0.5653 - val_loss: 6.8557 - val_acc: 0.5700
Epoch 75/92
 - 18s - loss: 6.9405 - acc: 0.5647 - val_loss: 6.8557 - val_acc: 0.5700
Epoch 76/92
 - 18s - loss: 6.9414 - acc: 0.5646 - val_loss: 6.8557 - val_acc: 0.5700
Epoch 77/92
 - 18s - loss: 6.9481 - acc: 0.5642 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 78/92
 - 18s - loss: 6.9510 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 79/92
 - 18s - loss: 6.9509 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 80/92
 - 18s - loss: 6.9509 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 81/92
 - 18s - loss: 6.9506 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 82/92
 - 18s - loss: 6.9507 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 83/92
 - 18s - loss: 6.9507 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 84/92
 - 18s - loss: 6.9508 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 85/92
 - 18s - loss: 6.9510 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 86/92
 - 18s - loss: 6.9510 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 87/92
 - 18s - loss: 6.9509 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 88/92
 - 18s - loss: 6.9508 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 89/92
 - 18s - loss: 6.9510 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 90/92
 - 18s - loss: 6.9508 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 91/92
 - 18s - loss: 6.9509 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Epoch 92/92
 - 18s - loss: 6.9509 - acc: 0.5640 - val_loss: 6.9078 - val_acc: 0.5667
Test accuracy: 0.5667
(900000,)
(100000,)
MaxAbs

(900000, 7)
(100000, 7)
Evalutation of best performing model:

    32/100000 [..............................] - ETA: 12s
   864/100000 [..............................] - ETA: 6s 
  1728/100000 [..............................] - ETA: 5s
  2592/100000 [..............................] - ETA: 5s
  3456/100000 [>.............................] - ETA: 5s
  4288/100000 [>.............................] - ETA: 5s
  5120/100000 [>.............................] - ETA: 5s
  5984/100000 [>.............................] - ETA: 5s
  6848/100000 [=>............................] - ETA: 5s
  7712/100000 [=>............................] - ETA: 5s
  8576/100000 [=>............................] - ETA: 5s
  9408/100000 [=>............................] - ETA: 5s
 10272/100000 [==>...........................] - ETA: 5s
 11136/100000 [==>...........................] - ETA: 5s
 12000/100000 [==>...........................] - ETA: 5s
 12864/100000 [==>...........................] - ETA: 5s
 13728/100000 [===>..........................] - ETA: 5s
 14592/100000 [===>..........................] - ETA: 5s
 15456/100000 [===>..........................] - ETA: 5s
 16320/100000 [===>..........................] - ETA: 5s
 17184/100000 [====>.........................] - ETA: 4s
 18048/100000 [====>.........................] - ETA: 4s
 18912/100000 [====>.........................] - ETA: 4s
 19776/100000 [====>.........................] - ETA: 4s
 20640/100000 [=====>........................] - ETA: 4s
 21504/100000 [=====>........................] - ETA: 4s
 22368/100000 [=====>........................] - ETA: 4s
 23232/100000 [=====>........................] - ETA: 4s
 24096/100000 [======>.......................] - ETA: 4s
 24960/100000 [======>.......................] - ETA: 4s
 25824/100000 [======>.......................] - ETA: 4s
 26688/100000 [=======>......................] - ETA: 4s
 27552/100000 [=======>......................] - ETA: 4s
 28416/100000 [=======>......................] - ETA: 4s
 29280/100000 [=======>......................] - ETA: 4s
 30144/100000 [========>.....................] - ETA: 4s
 31008/100000 [========>.....................] - ETA: 4s
 31872/100000 [========>.....................] - ETA: 4s
 32736/100000 [========>.....................] - ETA: 4s
 33600/100000 [=========>....................] - ETA: 3s
 34432/100000 [=========>....................] - ETA: 3s
 35296/100000 [=========>....................] - ETA: 3s
 36160/100000 [=========>....................] - ETA: 3s
 37024/100000 [==========>...................] - ETA: 3s
 37888/100000 [==========>...................] - ETA: 3s
 38752/100000 [==========>...................] - ETA: 3s
 39616/100000 [==========>...................] - ETA: 3s
 40448/100000 [===========>..................] - ETA: 3s
 41312/100000 [===========>..................] - ETA: 3s
 42176/100000 [===========>..................] - ETA: 3s
 43040/100000 [===========>..................] - ETA: 3s
 43904/100000 [============>.................] - ETA: 3s
 44768/100000 [============>.................] - ETA: 3s
 45632/100000 [============>.................] - ETA: 3s
 46496/100000 [============>.................] - ETA: 3s
 47360/100000 [=============>................] - ETA: 3s
 48224/100000 [=============>................] - ETA: 3s
 49088/100000 [=============>................] - ETA: 3s
 49952/100000 [=============>................] - ETA: 2s
 50816/100000 [==============>...............] - ETA: 2s
 51680/100000 [==============>...............] - ETA: 2s
 52544/100000 [==============>...............] - ETA: 2s
 53408/100000 [===============>..............] - ETA: 2s
 54272/100000 [===============>..............] - ETA: 2s
 55136/100000 [===============>..............] - ETA: 2s
 56000/100000 [===============>..............] - ETA: 2s
 56864/100000 [================>.............] - ETA: 2s
 57696/100000 [================>.............] - ETA: 2s
 58560/100000 [================>.............] - ETA: 2s
 59392/100000 [================>.............] - ETA: 2s
 60256/100000 [=================>............] - ETA: 2s
 61088/100000 [=================>............] - ETA: 2s
 61952/100000 [=================>............] - ETA: 2s
 62784/100000 [=================>............] - ETA: 2s
 63616/100000 [==================>...........] - ETA: 2s
 64448/100000 [==================>...........] - ETA: 2s
 65280/100000 [==================>...........] - ETA: 2s
 66144/100000 [==================>...........] - ETA: 2s
 67008/100000 [===================>..........] - ETA: 1s
 67840/100000 [===================>..........] - ETA: 1s
 68704/100000 [===================>..........] - ETA: 1s
 69536/100000 [===================>..........] - ETA: 1s
 70368/100000 [====================>.........] - ETA: 1s
 71232/100000 [====================>.........] - ETA: 1s
 72064/100000 [====================>.........] - ETA: 1s
 72896/100000 [====================>.........] - ETA: 1s
 73728/100000 [=====================>........] - ETA: 1s
 74560/100000 [=====================>........] - ETA: 1s
 75392/100000 [=====================>........] - ETA: 1s
 76224/100000 [=====================>........] - ETA: 1s
 77088/100000 [======================>.......] - ETA: 1s
 77952/100000 [======================>.......] - ETA: 1s
 78816/100000 [======================>.......] - ETA: 1s
 79680/100000 [======================>.......] - ETA: 1s
 80544/100000 [=======================>......] - ETA: 1s
 81408/100000 [=======================>......] - ETA: 1s
 82272/100000 [=======================>......] - ETA: 1s
 83136/100000 [=======================>......] - ETA: 1s
 84000/100000 [========================>.....] - ETA: 0s
 84864/100000 [========================>.....] - ETA: 0s
 85728/100000 [========================>.....] - ETA: 0s
 86560/100000 [========================>.....] - ETA: 0s
 87424/100000 [=========================>....] - ETA: 0s
 88288/100000 [=========================>....] - ETA: 0s
 89152/100000 [=========================>....] - ETA: 0s
 90016/100000 [==========================>...] - ETA: 0s
 90880/100000 [==========================>...] - ETA: 0s
 91744/100000 [==========================>...] - ETA: 0s
 92608/100000 [==========================>...] - ETA: 0s
 93472/100000 [===========================>..] - ETA: 0s
 94336/100000 [===========================>..] - ETA: 0s
 95200/100000 [===========================>..] - ETA: 0s
 96064/100000 [===========================>..] - ETA: 0s
 96928/100000 [============================>.] - ETA: 0s
 97792/100000 [============================>.] - ETA: 0s
 98656/100000 [============================>.] - ETA: 0s
 99520/100000 [============================>.] - ETA: 0s
100000/100000 [==============================] - 6s 60us/step
['6.624555253524781', '0.58447']
Best performing model chosen hyper-parameters:
{'Dense': 2956, 'epochs': 36, 'Dropout': 0.8897104326405169, 'optimizer': 0, 'Dense_10': 87, 'Dense_3': 2951, 'Dense_2': 922, 'Dense_1': 1788, 'Dense_7': 180, 'Dense_6': 2062, 'Dense_5': 2202, 'Dense_4': 295, 'Dense_9': 110, 'Dense_8': 2011, 'Dropout_1': 0.5461499863940397, 'Dropout_3': 0.15716268492531738, 'Dropout_2': 0.05753063853734175, 'Dropout_5': 0.43404126142165134, 'Dropout_4': 0.5442420919810019, 'Dropout_7': 0.5152808649614491, 'Dropout_6': 0.6975075528853121, 'Dropout_9': 0.23316134447477344, 'Dropout_8': 0.42522861686845626, 'Activation': 0}
