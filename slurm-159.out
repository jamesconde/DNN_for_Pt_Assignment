Using TensorFlow backend.
2018-07-09 10:49:05.220002: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-07-09 10:49:05.668398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-07-09 10:49:05.914066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:0b:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-07-09 10:49:06.181432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:0e:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-07-09 10:49:06.482089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:11:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-07-09 10:49:06.494920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3
2018-07-09 10:49:11.699234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-09 10:49:11.699573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3 
2018-07-09 10:49:11.699585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y Y Y 
2018-07-09 10:49:11.699590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N Y Y 
2018-07-09 10:49:11.699595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   Y Y N Y 
2018-07-09 10:49:11.699600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   Y Y Y N 
2018-07-09 10:49:11.701131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
2018-07-09 10:49:11.881882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0b:00.0, compute capability: 6.0)
2018-07-09 10:49:12.062876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 15135 MB memory) -> physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0e:00.0, compute capability: 6.0)
2018-07-09 10:49:12.245037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 15135 MB memory) -> physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:11:00.0, compute capability: 6.0)
>>> Imports:
#coding=utf-8

from __future__ import print_function

try:
    import numpy as np
except:
    pass

try:
    import h5py
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation
except:
    pass

try:
    from keras.models import Sequential
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from keras.utils import to_categorical
except:
    pass

try:
    from keras.layers import LeakyReLU, ELU
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

try:
    from workingwithpython import *
except:
    pass

try:
    from sklearn.model_selection import train_test_split
except:
    pass

try:
    from sklearn import preprocessing
except:
    pass

try:
    from macros_AWS import scale_x
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'add': hp.choice('add', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'add_1': hp.choice('add_1', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'add_2': hp.choice('add_2', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'optimizer': hp.choice('optimizer', ['adam','nadam','adamax']),
    }

>>> Data
   1: 
   2: """
   3: Data providing function:
   4: 
   5: This function is separated from create_model() so that hyperopt
   6: won't reload data for each evaluation run.
   7: """
   8: #(x_train, y_train), (x_test, y_test) = mnist.load_data()
   9: #x_train = x_train.reshape(60000, 784)
  10: #x_test = x_test.reshape(10000, 784)
  11: #x_train = x_train.astype('float32')
  12: #x_test = x_test.astype('float32')
  13: #x_train /= 255
  14: #x_test /= 255
  15: #nb_classes = 10
  16: #y_train = np_utils.to_categorical(y_train, nb_classes)
  17: #y_test = np_utils.to_categorical(y_test, nb_classes)
  18: from sklearn.model_selection import train_test_split
  19: from sklearn import preprocessing
  20: from macros_AWS import scale_x
  21: data_directory = '/home/rice/jmc32/Gridsearch_Data/'
  22: data_sample = 'PtRegression_for_DNN_Vars_MODE_15_noBitCompr_RPC_1m_redo.npy'
  23: scaler = 'robust'
  24: totalset = np.load(data_directory + data_sample)
  25: dataset, testset = train_test_split(totalset, test_size = 0.1)
  26: # Split into input (X) and output (Y) variables
  27: x_train_prescale = dataset[:,1:]
  28: y_train = dataset[:,0]
  29: x_test_prescale = testset[:,1:]
  30: y_test = testset[:,0]
  31: # Scale
  32: print(y_train.shape)
  33: print(y_test.shape)
  34: #print(numpy.matrix(y_train))
  35: x_train, x_test = scale_x(x_train_prescale, x_test_prescale, scaler)
  36: #min_max_scaler = preprocessing.MinMaxScaler()
  37: #x_test = min_max_scaler.fit_transform(x_train)
  38: #y_test = min_max_scaler.fit_transform(y_train)
  39: #x_train = min_max_scaler.fit_transform(x_train)
  40: #y_train = min_max_scaler.fit_transform(y_train)
  41: #x_test=x_test.reshape((900000, 7))
  42: #y_test=y_test.reshape((y_test.shape[0], 7))
  43: #x_train=x_train.reshape((x_train.shape[0], 7))
  44: #y_train=y_train.reshape((y_train.shape[0],  7))
  45: 
  46: print(x_train.shape)
  47: print(x_test.shape)
  48: #y_train= to_categorical(y_train)
  49: #y_test= to_categorical(y_test)
  50: #x_train= to_categorical(x_train)
  51: #x_test= to_categorical(x_test)
  52: 
  53: 
  54: 
  55: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     """
   4:     Model providing function:
   5: 
   6:     Create Keras model with double curly brackets dropped-in as needed.
   7:     Return value has to be a valid python dictionary with two customary keys:
   8:         - loss: Specify a numeric evaluation metric to be minimized
   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible
  10:     The last one is optional, though recommended, namely:
  11:         - model: specify the model just created so that we can later use it again.
  12:     """
  13:     model = Sequential()
  14:     model.add(Dense(100, input_dim=7))
  15:     model.add(space['add'])
  16:     model.add(Dense(100))
  17:     model.add(space['add_1'])
  18:     model.add(Dense(100))
  19:     model.add(space['add_2'])
  20: 
  21:     model.add(Dense(1))  
  22:     model.add(Activation('sigmoid'))
  23:   
  24:   
  25:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],
  26:                      optimizer=space['optimizer'])
  27: 
  28:     
  29:     model.fit(x_train, y_train,
  30:               batch_size=100,
  31:               epochs=2,
  32:               verbose=2,
  33:               validation_data=(x_test, y_test))
  34:     score, acc = model.evaluate(x_test, y_test, verbose=0)
  35:     print('Test accuracy:', acc)
  36:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}
  37: 
(900000,)
(100000,)
(900000, 7)
(100000, 7)
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 42s - loss: 0.1827 - acc: 0.9269 - val_loss: 0.1687 - val_acc: 0.9323
Epoch 2/2
 - 34s - loss: 0.1640 - acc: 0.9342 - val_loss: 0.1651 - val_acc: 0.9329
Test accuracy: 0.93286
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 36s - loss: 0.1774 - acc: 0.9289 - val_loss: 0.1649 - val_acc: 0.9335
Epoch 2/2
 - 35s - loss: 0.1614 - acc: 0.9348 - val_loss: 0.1626 - val_acc: 0.9332
Test accuracy: 0.93318
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 40s - loss: 0.1774 - acc: 0.9284 - val_loss: 0.1663 - val_acc: 0.9324
Epoch 2/2
 - 39s - loss: 0.1623 - acc: 0.9342 - val_loss: 0.1631 - val_acc: 0.9336
Test accuracy: 0.93364
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 39s - loss: 0.1753 - acc: 0.9299 - val_loss: 0.1634 - val_acc: 0.9335
Epoch 2/2
 - 38s - loss: 0.1608 - acc: 0.9348 - val_loss: 0.1626 - val_acc: 0.9342
Test accuracy: 0.93424
Train on 900000 samples, validate on 100000 samples
Epoch 1/2
 - 36s - loss: 0.1809 - acc: 0.9270 - val_loss: 0.1713 - val_acc: 0.9303
Epoch 2/2
 - 35s - loss: 0.1627 - acc: 0.9342 - val_loss: 0.1620 - val_acc: 0.9338
Test accuracy: 0.93383
(900000,)
(100000,)
(900000, 7)
(100000, 7)
Traceback (most recent call last):
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/DUMMYHyperasexamplerun.py", line 126, in <module>
    model_predictions = best_model.model.predict(Y_test)
  File "/home/rice/jmc32/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.py", line 1817, in predict
    check_batch_axis=False)
  File "/home/rice/jmc32/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/keras/engine/training.py", line 123, in _standardize_input_data
    str(data_shape))
ValueError: Error when checking : expected dense_13_input to have shape (7,) but got array with shape (1,)
('True negative total is ', 43613, 'out of', 100000)
('True positive total is ', 29252)
('False negative total is ', 26946)
('False positive total is ', 189)
('Any missed ones? ', 0)
