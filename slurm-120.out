Using TensorFlow backend.
>>> Imports:
#coding=utf-8

from __future__ import print_function

try:
    import numpy
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation
except:
    pass

try:
    from keras.models import Sequential
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from keras.utils import to_categorical
except:
    pass

try:
    from keras.layers import LeakyReLU
except:
    pass

try:
    from keras.layers import PReLU
except:
    pass

try:
    from keras.layers import ELU
except:
    pass

try:
    from keras.layers import ThresholdedReLU
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

try:
    from sklearn.model_selection import train_test_split
except:
    pass

try:
    from macros_AWS import scale_x
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'Dense': hp.choice('Dense', [1]+range(1)),
        'add': hp.choice('add', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'Dense_1': hp.choice('Dense_1', [1]+range(1)),
        'add_1': hp.choice('add_1', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'Dense_2': hp.choice('Dense_2', [1]+range(1)),
        'add_2': hp.choice('add_2', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'Activation': hp.choice('Activation', ['sigmoid']),
        'optimizer': hp.choice('optimizer', ['adam']),
        'Dense_3': hp.choice('Dense_3', [1]+range(1)),
        'Dense_4': hp.choice('Dense_4', [1]+range(1)),
    }

>>> Data
   1: 
   2: """
   3: Data providing function:
   4: 
   5: This function is separated from create_model() so that hyperopt
   6: won't reload data for each evaluation run.
   7: """
   8: #(x_train, y_train), (x_test, y_test) = mnist.load_data()
   9: #x_train = x_train.reshape(60000, 784)
  10: #x_test = x_test.reshape(10000, 784)
  11: #x_train = x_train.astype('float32')
  12: #x_test = x_test.astype('float32')
  13: #x_train /= 255
  14: #x_test /= 255
  15: #nb_classes = 10
  16: #y_train = np_utils.to_categorical(y_train, nb_classes)
  17: #y_test = np_utils.to_categorical(y_test, nb_classes)
  18: from sklearn.model_selection import train_test_split
  19: from macros_AWS import scale_x
  20: data_directory = '/home/rice/jmc32/Gridsearch_Data/'
  21: data_sample = 'PtRegression_for_DNN_Vars_MODE_15_noBitCompr_RPC_1m_redo.npy'
  22: scaler = 'robust'
  23: totalset = numpy.load(data_directory + data_sample)
  24: dataset, testset = train_test_split(totalset, test_size = 0.1)
  25: # Split into input (X) and output (Y) variables
  26: x_train_prescale = dataset[:,1:]
  27: y_train = dataset[:,0]
  28: x_test_prescale = testset[:,1:]
  29: y_test = testset[:,0]
  30: # Scale
  31: print(y_train.shape)
  32: print(y_test.shape)
  33: #print(numpy.matrix(y_train))
  34: x_train, x_test = scale_x(x_train_prescale, x_test_prescale, scaler)
  35: print(x_train.shape)
  36: print(x_test.shape)
  37: #y_train= to_categorical(y_train)
  38: #y_test= to_categorical(y_test)
  39: #x_train= to_categorical(x_train)
  40: #x_test= to_categorical(x_test)
  41: 
  42: 
  43: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     """
   4:     Model providing function:
   5: 
   6:     Create Keras model with double curly brackets dropped-in as needed.
   7:     Return value has to be a valid python dictionary with two customary keys:
   8:         - loss: Specify a numeric evaluation metric to be minimized
   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible
  10:     The last one is optional, though recommended, namely:
  11:         - model: specify the model just created so that we can later use it again.
  12:     """
  13:     model = Sequential()
  14:     model.add(Dense(space['Dense'], input_dim=7))
  15:     model.add(space['add'])
  16:     model.add(Dense(space['Dense_1']))
  17:     model.add(space['add_1'])
  18:     model.add(Dense(space['Dense_2']))
  19:     model.add(space['add_2'])
  20:     model.add(Dense(1))
  21:     
  22:     model.add(Activation(space['Activation']))
  23: 
  24: 
  25:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],
  26:                   optimizer=space['optimizer'])
  27: 
  28:     model.fit(x_train, y_train,
  29:               batch_size=space['Dense_3'],
  30:               epochs=space['Dense_4'],
  31:               verbose=2,
  32:               validation_data=(x_test, y_test))
  33:     score, acc = model.evaluate(x_test, y_test, verbose=0)
  34:     print('Test accuracy:', acc)
  35:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}
  36: 
(900000,)
(100000,)
Unexpected error: <type 'exceptions.ValueError'>
Traceback (most recent call last):
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/Hyperasexamplerun.py", line 102, in <module>
    trials=Trials())
  File "/home/rice/jmc32/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/hyperas/optim.py", line 67, in minimize
    verbose=verbose)
  File "/home/rice/jmc32/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/hyperas/optim.py", line 101, in base_minimizer
    from temp_model import keras_fmin_fnct, get_space
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/temp_model.py", line 114, in <module>
    x_train, x_test = scale_x(x_train_prescale, x_test_prescale, scaler)
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/macros_AWS.py", line 63, in scale_x
    X_test=numpy.concatenate((X_test,x00), axis=1)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
('True negative total is ', 43613, 'out of', 100000)
('True positive total is ', 29252)
('False negative total is ', 26946)
('False positive total is ', 189)
('Any missed ones? ', 0)
