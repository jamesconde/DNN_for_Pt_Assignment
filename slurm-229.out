Using TensorFlow backend.
>>> Imports:
#coding=utf-8

from __future__ import print_function

try:
    import numpy as np
except:
    pass

try:
    import h5py
except:
    pass

try:
    from hyperopt import Trials, STATUS_OK, tpe
except:
    pass

try:
    from keras.datasets import mnist
except:
    pass

try:
    from keras.layers.core import Dense, Dropout, Activation
except:
    pass

try:
    from keras.models import Sequential
except:
    pass

try:
    from keras.utils import np_utils
except:
    pass

try:
    from keras.utils import to_categorical
except:
    pass

try:
    from keras.layers import LeakyReLU, ELU
except:
    pass

try:
    from hyperas import optim
except:
    pass

try:
    from hyperas.distributions import choice, uniform
except:
    pass

try:
    from workingwithpython import *
except:
    pass

try:
    from sklearn.model_selection import train_test_split
except:
    pass

try:
    from sklearn import preprocessing
except:
    pass

try:
    from macros_AWS import scale_x
except:
    pass

>>> Hyperas search space:

def get_space():
    return {
        'add': hp.choice('add', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'add_1': hp.choice('add_1', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'add_2': hp.choice('add_2', [LeakyReLU(alpha=0.1),Activation('relu'),ELU(alpha=1.0)]),
        'optimizer': hp.choice('optimizer', ['adam','nadam','adamax']),
    }

>>> Data
   1: 
   2: """
   3: Data providing function:
   4: 
   5: This function is separated from create_model() so that hyperopt
   6: won't reload data for each evaluation run.
   7: """
   8: #(x_train, y_train), (x_test, y_test) = mnist.load_data()
   9: #x_train = x_train.reshape(60000, 784)
  10: #x_test = x_test.reshape(10000, 784)
  11: #x_train = x_train.astype('float32')
  12: #x_test = x_test.astype('float32')
  13: #x_train /= 255
  14: #x_test /= 255
  15: #nb_classes = 10
  16: #y_train = np_utils.to_categorical(y_train, nb_classes)
  17: #y_test = np_utils.to_categorical(y_test, nb_classes)
  18: from sklearn.model_selection import train_test_split
  19: from sklearn import preprocessing
  20: from macros_AWS import scale_x
  21: data_directory = '/home/rice/jmc32/Gridsearch_Data/'
  22: data_sample = 'PtRegression_for_DNN_Vars_MODE_15_noBitCompr_RPC_1m_redo.npy'
  23: scaler = 'robust'
  24: totalset = np.load(data_directory + data_sample)
  25: dataset, testset = train_test_split(totalset, test_size = 0.1)
  26: # Split into input (X) and output (Y) variables
  27: x_train_prescale = dataset[:,1:]
  28: y_train = dataset[:,0]
  29: x_test_prescale = testset[:,1:]
  30: y_test = testset[:,0]
  31: # Scale
  32: print(y_train.shape)
  33: print(y_test.shape)
  34: #print(numpy.matrix(y_train))
  35: x_train, x_test = scale_x(x_train_prescale, x_test_prescale, scaler)
  36: #min_max_scaler = preprocessing.MinMaxScaler()
  37: #x_test = min_max_scaler.fit_transform(x_train)
  38: #y_test = min_max_scaler.fit_transform(y_train)
  39: #x_train = min_max_scaler.fit_transform(x_train)
  40: #y_train = min_max_scaler.fit_transform(y_train)
  41: #x_test=x_test.reshape((900000, 7))
  42: #y_test=y_test.reshape((y_test.shape[0], 7))
  43: #x_train=x_train.reshape((x_train.shape[0], 7))
  44: #y_train=y_train.reshape((y_train.shape[0],  7))
  45: 
  46: print(x_train.shape)
  47: print(x_test.shape)
  48: #y_train= to_categorical(y_train)
  49: #y_test= to_categorical(y_test)
  50: #x_train= to_categorical(x_train)
  51: #x_test= to_categorical(x_test)
  52: 
  53: 
  54: 
  55: 
>>> Resulting replaced keras model:

   1: def keras_fmin_fnct(space):
   2: 
   3:     """
   4:     Model providing function:
   5: 
   6:     Create Keras model with double curly brackets dropped-in as needed.
   7:     Return value has to be a valid python dictionary with two customary keys:
   8:         - loss: Specify a numeric evaluation metric to be minimized
   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible
  10:     The last one is optional, though recommended, namely:
  11:         - model: specify the model just created so that we can later use it again.
  12:     """
  13:     model = Sequential()
  14:     model.add(Dense(100, input_dim=7))
  15:     model.add(space['add'])
  16:     model.add(Dense(100))
  17:     model.add(space['add_1'])
  18:     model.add(Dense(100))
  19:     model.add(space['add_2'])
  20: 
  21:     model.add(Dense(1))  
  22:     model.add(Activation('sigmoid'))
  23:   
  24:   
  25:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],
  26:                      optimizer=space['optimizer'])
  27: 
  28:     
  29:     model.fit(x_train, y_train,
  30:               batch_size=100,
  31:               epochs=2,
  32:               verbose=2,
  33:               validation_data=(x_test, y_test))
  34:     score, acc = model.evaluate(x_test, y_test, verbose=0)
  35:     print('Test accuracy:', acc)
  36:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}
  37: 
Unexpected error: <type 'exceptions.IndentationError'>
Traceback (most recent call last):
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/DUMMYHyperasexamplerun.py", line 124, in <module>
    trials=Trials())
  File "/home/rice/jmc32/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/hyperas/optim.py", line 67, in minimize
    verbose=verbose)
  File "/home/rice/jmc32/anaconda2/envs/tensorflow-gpu/lib/python2.7/site-packages/hyperas/optim.py", line 101, in base_minimizer
    from temp_model import keras_fmin_fnct, get_space
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/temp_model.py", line 100, in <module>
    from macros_AWS import scale_x
  File "/home/rice/jmc32/DNN_for_Pt_Assignment-master/DNN_Hyperparameters/macros_AWS.py", line 91
    return X_train, X_test
    ^
IndentationError: unexpected indent
('True negative total is ', 43746, 'out of', 100000)
('True positive total is ', 0)
('False negative total is ', 56254)
('False positive total is ', 0)
('Any missed ones? ', 0)
